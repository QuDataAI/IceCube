{"cells":[{"cell_type":"markdown","metadata":{"id":"KHM5egnUXQgy"},"source":["# Model Transformer\n","\n","Training the Transformer model\n","\n","(!) The training data on google-driver is prepared by the notebook:<br>\n","https://github.com/QuDataAI/IceCube/IceCube-Dataset-kaggle\n","\n","A description of the architecture can be found here:<br>\n","https://qudata.com/projects/icecube-neutrino/en/index.html"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tB39TDeyZGZs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681995231678,"user_tz":-180,"elapsed":24124,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"}},"outputId":"a0cf08b6-3f2f-495a-9a02-0cbf0995bb8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting update\n","  Downloading update-0.0.1-py2.py3-none-any.whl (2.9 kB)\n","Collecting qunet\n","  Downloading QuNet-0.0.4-py3-none-any.whl (23 kB)\n","Collecting style==1.1.0\n","  Downloading style-1.1.0-py2.py3-none-any.whl (6.4 kB)\n","Installing collected packages: style, qunet, update\n","Successfully installed qunet-0.0.4 style-1.1.0 update-0.0.1\n"]}],"source":["!pip  install update qunet             # it's our lib for DL\n","!pip -q  install torchinfo\n","\n","import os, gc, sys, copy, time, datetime, math, random,  psutil\n","import numpy as np, pandas as pd, matplotlib.pyplot as plt\n","from   pathlib   import Path        \n","from   tqdm.auto import tqdm\n","import pyarrow, pyarrow.parquet as pq     \n","\n","import torch\n","from   torch import nn\n","from   torchinfo import summary"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1681995243145,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"},"user_tz":-180},"id":"Gy1RIUebW-Dj","outputId":"6ed7115c-f997-4e17-e8c2-ef7f4546d23e"},"outputs":[{"output_type":"stream","name":"stdout","text":["T_max:512, AF:48, frozen:False, loss:azze, ka_reg:0, ze_reg:0, az_reg:0, lr:0.001, batch_size:128, batch_max:256, params:0, samples:0, steps:0, last:0, score:0, device:cuda, plt:<function CFG.plt at 0x7f8d1c6a5790>, \n","Your runtime has 12.7 gigabytes of available RAM\n","\n","Thu Apr 20 12:54:02 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","CPU times: user 15.3 ms, sys: 5.86 ms, total: 21.2 ms\n","Wall time: 268 ms\n"]}],"source":["%%time\n","COPY_FROM_DRIVE     = True        # copy dataset from google drive\n","DATA_KIND           = \"00\"        # kind of data (DROP_AUX, DOMS_AGG)\n","#===============================================================================\n","\n","class CFG:   \n","    T_max    =  512               # max tokens (pulses in event)\n","    AF       = 24*2               # number of aggregated event features\n","\n","    frozen   = False              # freeze feature generator and transformer\n","\n","    loss     = 'azze'             # kind of loss function: cos, prod, vMF, k2,  k2ze\n","    ka_reg     = 0                # kappa length regularization\n","    ze_reg     = 0                # zenith angle error reduction\n","    az_reg     = 0                # azimuthal angle error reduction\n","\n","    lr         = 1e-3             # current learning rate\n","    batch_size = 128              # batch size for max pulses\n","    batch_max  = 256              # maximum allowed batch size for any length\n","\n","    params     = 0                # number of parameters in the model\n","    samples    = 0                # number of events passed through training\n","    steps      = 0                # number of steps taken by the optimizer \n","    last       = 0                # when was the best validation metric last\n","    score      = 0                # best validation metric\n","\n","    device     = 'cuda'           # computing device\n","\n","    def get(end=\", \"):\n","        \"\"\" output of config parameters \"\"\"\n","        return \"\".join([f\"{k}:{v}{end}\" for k,v in CFG.__dict__.items() if not k.startswith(\"__\") and k not in [\"get\", \"par\"] ])\n","\n","    def plt(end=\"\\n\"):\n","        \"\"\" output of config parameters for the plot \"\"\"\n","        return \"\".join([f\" {k:7s}:{v}{end}\" for k,v in CFG.__dict__.items() if not k.startswith(\"__\") and k not in [\"get\",\"plt\", \"V\",  \"params\", \"device\", \"lr\",  \"best\", \"is_sqr\",\"is_cat\",\"is_pos\",\"is_rnn\",\"is_agg\",\"is_emb\",\"is_abs\",\"is_reg\",\"is_rho\",\"last\"] ])\n","\n","print(CFG.get())\n","#===============================================================================\n","from psutil import virtual_memory\n","print(f'Your runtime has {(virtual_memory().total / 1024**3):.1f} gigabytes of available RAM\\n')\n","gpu_info = !nvidia-smi\n","print('\\n'.join(gpu_info))\n","#===============================================================================\n","def info(text, pref=\"\", end=\"\\n\"):\n","    \"\"\" \n","    Information about the progress of calculations (time and memory) \n","    \"\"\"\n","    gc.collect()\n","    ram, t = psutil.virtual_memory().used / 1024**3,  time.time()    \n","    print(f\"{pref}{(t-info.beg)/60:5.1f}m[{t-info.last:+5.1f}s] {ram:6.3f}Gb > {text}\",end=end)\n","    info.last = time.time(); \n","info.beg = info.last = time.time()"]},{"cell_type":"markdown","source":["## Copy dataset from google drive"],"metadata":{"id":"Kh_2CZcKooGC"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["a11742c33335441db0ffdfa63a290a94","86ee357809fd4fb483bc5903628412bf","96ac6e701ad1476fafc963be02dd1117","63ecdd23e13248c58f2378894a88e079","d152c463d6e44a369ae22988998b6c18","57ecaf1bfe3f492e83e343c4fe318de5","dd3a1500c47145cabec6652cf62e1a77","272870d52eab467ea0474f6986f9ae39","2f28328d5c91458ab4bdcd054a5fa04b","7b4718a01b0b4d249ef6291e0c98849a","6840455cfa0946e4944b22e42447ffad","9c3e02e9d6644787ab18858fe720417b","3a5724f18f454b779649d31a1841a901","9b11f592bf0b436e8b94bb80d7ec1449","8a30220b696a4d06b25f5e9d5dde77db","9fe82fc0ad9340d385b6b504dc3c1305","b01405dd2ce148e8bd7936d954dab621","67a3ee80386c42a4a3f155f3a0791981","5c30a7c4c4dc4229bec4ae4e1a118374","c45483718544434db6b97b4e1fd869ab","b3b98662e36f42b88eeef3f0a82a1115","4b7392def50a4b4bad7fef924384df3c"]},"executionInfo":{"elapsed":33863,"status":"ok","timestamp":1681995281836,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"},"user_tz":-180},"id":"_AlZ4FltnlUK","outputId":"7a1d90fa-4525-4168-b59c-79ad8f72ec5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["  0.0m[ +0.4s]  1.103Gb > Begin\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a11742c33335441db0ffdfa63a290a94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c3e02e9d6644787ab18858fe720417b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['trn/DOMS_AGG_64/pack_02.pt']\n","['val/pack_01.pt']\n","CPU times: user 375 ms, sys: 120 ms, total: 495 ms\n","Wall time: 33.6 s\n"]}],"source":["%%time\n","info.beg = info.last = time.time()\n","info(\"Begin\")\n","\n","ROOT    = \"/content/drive/MyDrive/IceCube/IceCube-Dataset/\"    # root folder of all datasets\n","\n","FOLDER_TRN  = \"DOMS_AGG_64\"                                        # folder of dataset\n","FILES_TRN   = [f\"pack_{p:02d}.pt\" for p in range(2, 2+1)]      # list of files to train\n","FILES_VAL   = [\"DOMS_AGG_64/pack_01.pt\"]                           # list of files to validate\n","\n","if COPY_FROM_DRIVE:\n","    !cp \"{ROOT}{FOLDER_TRN}/doms.pt\"  /content/    \n","    !mkdir \"trn\"\n","    !mkdir \"val\"\n","    !mkdir \"trn/{FOLDER_TRN}\"\n","    \n","    for file in tqdm(FILES_TRN):                               # copy training dataset\n","        !cp \"{ROOT}{FOLDER_TRN}/{file}\"  \"trn/{FOLDER_TRN}\"    \n","        \n","    for file in tqdm(FILES_VAL):                               # copy validation dataset\n","        !cp \"{ROOT}{file}\"  \"val\"    \n","\n","# just in case, we read all the files\n","FILES_TRN = [f\"trn/{FOLDER_TRN}/\" + en.name for en in os.scandir(f\"trn/{FOLDER_TRN}/\") if en.is_file()]\n","FILES_VAL = [\"val/\" + en.name for en in os.scandir(\"val/\") if en.is_file()]\n","random.shuffle(FILES_TRN)    \n","print(FILES_TRN)\n","print(FILES_VAL)"]},{"cell_type":"markdown","metadata":{"id":"LnmBBSSyYDKX"},"source":["## Class Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1080,"status":"ok","timestamp":1681995282906,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"},"user_tz":-180},"id":"PEjyJVXEYFA7","outputId":"f946ee12-2c04-460c-a4f7-362645a74b5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["  0.6m[+34.1s]  1.303Gb > load doms.pt: ['x', 'y', 'z', 'core', 'a', 'r'],  DOMS:torch.Size([5160, 6])\n","DOMS: torch.Size([5160, 6])\n"]}],"source":["class Dataset:\n","    \"\"\"    \n","    Data loading class.\n","    The data is a dictionary in which the key is the length of the sequence.\n","    For the motivation for this structure, see \n","    https://qudata.com/projects/icecube-neutrino/en/transformer.html#dataset\n","    \"\"\"\n","    def __init__(self, files, batch_size, shuffle, device, drop, aux=False):\n","        \"\"\" \n","        data - a dictionary, its keys are the length of the sequence in pulses, \n","        and the values are a list:\n","                * EVENT_ID:  (B,1)    - event id                                \n","                * SENSOR_ID: (B,T)    - sensor_id for each pulse (token)\n","                * FEAT:      (B,T,F)  - F features for each pulse (token)     \n","                * AGG:       (B, FA)  - aggregate features\n","                * Y:         (B,3)    - (nx, ny, nz) - target direction (unit vector)\n","        \"\"\"        \n","        self.files      = files       # list of files with data packs\n","        self.shuffle    = shuffle     # mix minibatch\n","        self.batch_size = batch_size  # batch size for max pulses\n","        self.batch_max  = batch_size  # maximum batch size for any number of pulses\n","        self.T_max      = 100         # maximum number of pulses\n","        self.file_id    = 0           # current file number\n","        self.device     = device      # computing device\n","        \n","        self.epoch      = 0           # number of epochs after loading a new pack\n","        self.data       = {}          # data with packs \n","        self.is_T1      = 0           # minimum pulse filter\n","        self.is_T2     = 1e8          # filter by the maximum number of pulses\n","        \n","        info(f\"Create dataset with {len(files)} files\")\n","        \n","    def load_next(self, verbose = False):\n","        if verbose: info(f\"load_next> started: file_id={self.file_id}\")\n","        del self.data        \n","        self.epoch = 0\n","        state = torch.load(self.files[self.file_id])\n","        self.cols_df     = state['cols_df']\n","        self.cols_agg_df = state['cols_agg_df']        \n","        self.data = state['data']\n","        \n","        self.file_id += 1\n","        self.file_id = self.file_id % len(self.files)\n","        if verbose: info(f\"load_next loaded,  tokens: {len(self.data)}\")\n","\n","        if self.device != 'cpu':\n","            for k in self.data:\n","                for i in range(len(self.data[k])):\n","                    self.data[k][i] = self.data[k][i].to(self.device)\n","            if verbose: info(f\"load_next sended to GPU\")\n","\n","        self.create_batches()          # create batches\n","        self.batch_id   = 0            # current batch        \n","\n","    def set(self, batch_size, batch_max, T_max, is_T1=0, is_T2=1e8):\n","        self.batch_size = batch_size\n","        self.batch_max  = batch_max\n","        self.T_max      = T_max\n","        self.is_T1      = is_T1\n","        self.is_T2      = is_T2\n","        self.create_batches()\n","\n","    def create_batches(self):      \n","        \"\"\" создать ссылки на индексы начала и конца батча \"\"\"         \n","        self.batches    = []           # list of pointers to batch  [ (T, idx1, idx2) ]\n","        for T,v in self.data.items():  # create pointers to batches [ (T, idx1, idx2) ]\n","            if self.is_T1 <= T and T <= self.is_T2:\n","                batch_size = min(int(self.batch_size * (self.T_max/T)**2),  self.batch_max)                \n","                for i in range(0, v[0].shape[0], batch_size):\n","                    self.batches.append((T, i, i + batch_size))\n","\n","    def reset(self):        \n","        self.batch_id   = 0            \n","        if self.shuffle:\n","            for k in self.data:         # shuffle all samples:                \n","                idx = torch.randperm( len(self.data[k][0]), device=self.device )\n","                for i in range(len(self.data[k])):\n","                    self.data[k][i] = self.data[k][i][idx]            \n","            random.shuffle(self.batches) \n","\n","    def __next__(self):        \n","        if self.batch_id >= len(self.batches):\n","            self.epoch += 1\n","            self.batch_id = 0\n","            raise StopIteration  \n","\n","        p = self.batches[self.batch_id]\n","        data  = self.data[p[0]]\n","        self.batch_id += 1                                                                #!!!!!!!!!!!!!!!!\n","\n","        # (B,)    (B,T)    (B,T,F)  (B,24*2)  (B,3) \n","        EVENT_ID, SENSOR_ID, FEAT,  AGG,  Y = data[0][p[1]:p[2]], data[1][p[1]:p[2]], data[2][p[1]:p[2]], data[3][p[1]:p[2], 0: CFG.AF ], data[4][p[1]:p[2]]  \n","        return EVENT_ID, SENSOR_ID, FEAT, AGG, Y, None # (last ERR)\n","\n","    def __iter__(self):\n","        return self\n","    \n","    def __len__(self):\n","        return len(self.batches)     \n","\n","#===============================================================================\n","\n","def load_doms(fname=\"doms.pt\"):\n","    \"\"\"\n","    Loading sensor parameters\n","    \"\"\"\n","    state = torch.load(fname)\n","    DOMS  = state['data']\n","    info(f\"load doms.pt: {state['cols']},  DOMS:{DOMS.shape}\")\n","    return DOMS\n","\n","DOMS = load_doms()\n","print(\"DOMS:\", DOMS.shape)"]},{"cell_type":"markdown","metadata":{"id":"9ytu6iNCUDzx"},"source":["##  Create Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2999,"status":"ok","timestamp":1681995285902,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"},"user_tz":-180},"id":"6jiM7JRNBsl-","outputId":"d003958d-a022-46e5-b55a-551a2e810f67"},"outputs":[{"output_type":"stream","name":"stdout","text":["  0.6m[ +0.1s]  1.303Gb > Create dataset with 1 files\n","  0.6m[ +0.1s]  1.303Gb > Create dataset with 1 files\n","  0.6m[ +0.1s]  1.303Gb > load_next> started: file_id=0\n","  0.6m[ +1.7s]  2.419Gb > load_next loaded,  tokens: 54\n","  0.6m[ +0.1s]  2.421Gb > trn: loaded, next file_id 0\n","  0.6m[ +0.1s]  2.421Gb > load_next> started: file_id=0\n","  0.6m[ +0.9s]  3.540Gb > load_next loaded,  tokens: 53\n","  0.6m[ +0.1s]  3.541Gb > val: loaded, next file_id 0\n","  0.6m[ +0.1s]  3.541Gb > T_max:512, AF:48, frozen:False, loss:azze, ka_reg:0, ze_reg:0, az_reg:0, lr:0.001, batch_size:128, batch_max:256, params:0, samples:0, steps:0, last:0, score:0, device:cuda, plt:<function CFG.plt at 0x7f8d1c6a5790>, \n"]}],"source":["dataset_trn = Dataset(FILES_TRN,  batch_size=CFG.batch_size, shuffle=True, device='cpu', drop=False)\n","dataset_val = Dataset(FILES_VAL,  batch_size=CFG.batch_size, shuffle=True, device='cpu', drop=False)\n","\n","dataset_trn.load_next(True)\n","info(f\"trn: loaded, next file_id {dataset_trn.file_id}\")\n","\n","dataset_val.load_next(True)\n","random.shuffle(dataset_val.batches)  # not large first!!!\n","info(f\"val: loaded, next file_id {dataset_val.file_id}\")\n","\n","dataset_trn.file_id = 0 # set first file for loading\n","dataset_val.file_id = 0 \n","info(CFG.get())"]},{"cell_type":"markdown","metadata":{"id":"51lb7wjh_P_h"},"source":["## Plot training history"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gFYSMdtS_Ql6","executionInfo":{"status":"ok","timestamp":1681995285902,"user_tz":-180,"elapsed":9,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"}}},"outputs":[],"source":["def plot(history, checks, labels, xmin=0, xmax=None, ymin=1.0, ymax=1.2, ticks=21, info=\"\", w=12, h=5, title_short=False):\n","    \"\"\" \n","    Creating a trainig process plot\n","    (CFG.samples, score_trn, score_val, kappa_trn, kappa_val, CFG.lr, tm_trn, tm_val) \n","    \"\"\"\n","    from matplotlib.ticker import FormatStrFormatter        \n","    xmax = len(history) if xmax is None else xmax\n","    hist = np.array(history)[xmin: xmax].transpose()   \n","    chck = np.array(checks)    \n","    \n","    plt.figure(figsize=(w,h), facecolor ='w')\n","    ax1 = plt.subplot(1,1,1); ax1.grid(ls=':')     \n","    plt.xlabel('1m samples'); plt.ylabel('error');     \n","    plt.text((hist[0,0]+0.8*(hist[0,-1]-hist[0,0]))/1e6, ymin+0.8*(ymax-ymin), info, fontname=\"monospace\", fontsize=8)\n","    #plt.text(hist[0,0]/1e6, ymin, CFG.plt(), fontname=\"monospace\", fontsize=8)\n","    ax1.set_ylim(ymin,ymax);  ax1.set_yticks(np.linspace(ymin, ymax, ticks))  \n","    ax1.plot   (hist[0]/1e6, hist[1], 'darkblue', linewidth=0.5);                 # err trn\n","    ax1.plot   (hist[0]/1e6, hist[2], 'g', linewidth=1.5);                        # err val\n","    if ymin < 1.00 and 1.00 < ymax: ax1.axhline(y=1.000, color='gray', linestyle='-', linewidth=0.5)\n","    if ymin < 1.10 and 1.10 < ymax: ax1.axhline(y=1.100, color='gray', linestyle='-', linewidth=0.5)\n","    if ymin < 1.02 and 1.02 < ymax: ax1.axhline(y=1.020, color='gray', linestyle='-', linewidth=0.5)    \n","    best = 1.51\n","    for c in chck:\n","        if c[0] >= hist[0,0] and c[0] <= hist[0,-1]:\n","            ax1.scatter(c[0]/1e6, c[1], s=7, c='g', edgecolors='black')            \n","            if c[1] < best: best = c[1]\n","\n","    if title_short:\n","        plt.title(fr\"[{CFG.score:.3f}] (trn:{hist[1,-1]:.4f}, val:{hist[2,-1]:.4f}, best:{best:.4f}) (az:{hist[3][-1]:.3f}, ze:{hist[4][-1]:.3f}, ka:{hist[-4][-1]:.2f})\")\n","    else:\n","        plt.title(fr\"[{CFG.score:.3f}] (trn:{hist[1,-1]:.4f}, val:{hist[2,-1]:.4f}, best:{best:.4f}) (az:{hist[3][-1]:.3f}, ze:{hist[4][-1]:.3f}, ka:{hist[-4][-1]:.2f}) > s={hist[0,-1]/1e6:.0f}m; (trn:{hist[-2,-1]:.2f}, val:{hist[-1,-1]:.2f})m/$10^6$) tot:{hist[-2].sum():.1f}m; pars={ModelCFG.params/1000:.0f}k\")                           \n","    ax1.legend(['trn', 'val'], loc='upper left', frameon = False)        \n","    ax1.tick_params(axis='y', colors='g')\n","    ax1.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n","    for lb in labels:    \n","        if lb[0] >= hist[0,0] and lb[0] <= hist[0,-1]:\n","            ax1.vlines(lb[0]/1e6, ymin, ymax, linestyles=':', color='gray')\n","            ax1.text(lb[0]/1e6,   ymin+0.001, lb[2])\n","    if False:\n","        ax2 = ax1.twinx(); ax2.set_ylim(0.000, 1.200) #ax2.set_ylabel(\"loss\");     \n","        ax2.plot(hist[0]/1e6, hist[3], \"--\",  color='darkgreen', linewidth=1)    # az_err\n","        ax2.plot(hist[0]/1e6, hist[4], \"--\", color='g', linewidth=1)             # ze_err\n","        ax2.legend(['az', 'ze'], loc='center right', frameon = False)\n","        ax2.tick_params(axis='y', colors='g')\n","        ax2.spines[\"right\"].set_position((\"outward\", 70))\n","        ax2.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n","\n","    ax3 = ax1.twinx(); \n","    ax3.set_yscale('log'); ax3.set_ylim(1e-6, 1e-1) #ax3.set_ylabel(\"log10(lr)\");     \n","    ax3.plot(hist[0]/1e6, hist[-3], \":\", color='darkred')             # lr    \n","    ax3.legend(['lr'], loc='upper right', frameon = False)\n","    ax3.tick_params(axis='y', colors='darkred')\n","    \n","    if True:\n","        ax4 = ax1.twinx(); #ax4.set_ylabel(\"kappa\")    \n","        ax4.plot(hist[0]/1e6, hist[-4], \"-r\", linewidth=0.5, alpha=0.5)             # kappa\n","        ax4.legend(['kappa'], loc='upper center', frameon = False)\n","        ax4.spines[\"right\"].set_position((\"outward\", 40))\n","        ax4.set_ylim((0, max(1, np.max(hist[-4]))))\n","        ax4.tick_params(axis='y', colors='r')\n","\n","    plt.show()    \n","\n","def vector2angles(n, eps=1e-8):\n","    \"\"\"  Get spherical angles of vector n: (B,3) \"\"\"                \n","    n = n / (np.linalg.norm(n, axis=1, keepdims=True) + eps)                             \n","    azimuth = np.arctan2( n[:,1],  n[:,0])    \n","    azimuth[azimuth < 0] += 2*np.pi                                \n","    zenith = np.arccos( n[:,2].clip(-1,1) )                                    \n","    return azimuth, zenith    \n"]},{"cell_type":"markdown","metadata":{"id":"FHhGWzB0cPYW"},"source":["## Model"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Gk889UiacRlw","executionInfo":{"status":"ok","timestamp":1681995288019,"user_tz":-180,"elapsed":3,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"}}},"outputs":[],"source":["from qunet.old import MLP, CNN, TransformerBlock, PointsBlock\n","\n","#===============================================================================\n","\n","class FeatureGenerator(nn.Module):\n","    def __init__(self, cfg, doms, V=5160):\n","        \"\"\" \n","        Feature generator. \n","        Gets the original pulse features, returns a tensor (B,T,E)\n","        V - number of sensors (embedding vocab) from sensors_df    \n","        \"\"\"\n","        super(FeatureGenerator, self).__init__()      \n","\n","        dom_feat = 4                                 # {x,y,z,core}\n","        if cfg.is_abs and not cfg.is_rho:            # {x,y,z,core,a} \n","            dom_feat = 5        \n","        else:                                        # {x,y,z,core,a,r}\n","            dom_feat = 6          \n","\n","        self.dom = nn.Embedding(V, dom_feat,_weight=doms[:,:dom_feat]).requires_grad_(False)\n","        self.emb = nn.Embedding(V, cfg.SE) if cfg.is_emb else None # sensor embedding                \n","             \n","        self.fin = MLP(dict(input=24, hidden=64, output=7)) if cfg.is_fin else None\n","\n","        F = dom_feat+cfg.F                           # {x,y,z,core [,a]} + {t,q,aux}\n","        if cfg.is_fin:\n","            F += self.fin.bias.shape[0]\n","        if cfg.is_emb:  \n","            F += cfg.SE                              # add sensor SE embedding\n","        self.mlp = MLP(dict(input=F, hidden=cfg.Hin, output=cfg.n_embd)) if cfg.Hin > 0 else nn.Linear(F, cfg.n_embd)\n","\n","    def forward(self, SENSOR_ID, FEAT):                       \n","        s  = self.dom(SENSOR_ID)                     # (B,T,5)   x,y,z,core,a,r  \n","        if self.emb is None:\n","            x  = torch.cat([s, FEAT], dim=2)         # (B,T,E0)  pulse feat  +  'aux','q','t'    \n","            if self.fin is not None:\n","                T = x.shape[1]\n","                f = self.fin(FEAT[24:])              # (B,7)\n","                f = f.unsqueeze(1).expand(-1,T,-1)   # (B,T,7)\n","                x = torch.cat([x,f], dim=2)          # (B,T,E0+7) = (B,T,16)\n","            x  = self.mlp(x)                         # (B,T,E)   increase num of features            \n","        else:\n","            em = self.emb(SENSOR_ID)\n","            x  = torch.cat([s, FEAT, em], dim=2)     # (B,T,F+6+SE) concat with pulse features       \n","            x  = self.mlp(x)                         # (B,T,E)   increase num of features            \n","        return x\n","#-------------------------------------------------------------------------------\n","\n","class Transformer(nn.Module):\n","    def __init__(self, cfg, drop=0):\n","        \"\"\" \n","        Transformer (B,T,E) -> (B,T,E) \n","        \"\"\"\n","        super().__init__()     \n","        if cfg.is_pnt:\n","            self.blocks= nn.ModuleList([PointsBlock(     dict(emb=cfg.n_embd, res=cfg.res)) for _ in range(cfg.L)])         \n","        else: \n","            self.blocks= nn.ModuleList([TransformerBlock(dict(emb=cfg.n_embd, res=cfg.res, att={'heads': 8})) for _ in range(cfg.L)])         \n","        self.drop = nn.Dropout(drop)\n","        self.ln   = nn.LayerNorm(cfg.n_embd)        \n","\n","    def forward(self, x):\n","        x   = self.drop(x)              \n","        x   = self.ln(x)                             # layer normalization (? batch)\n","\n","        for i, block in enumerate(self.blocks):  \n","            if CFG.frozen and self.training and i > CFG.L_frozen: torch.set_grad_enabled(True) \n","            x = block(x)                             # (B,T,E)            \n","        return x\n","#-------------------------------------------------------------------------------\n","\n","class Integrator(nn.Module):\n","    def __init__(self, cfg):\n","        \"\"\" \n","        Collects features from all pulses into one vector (B,T,E) -> (B,E) \n","        \"\"\"\n","        super().__init__()               \n","        self.ln    = nn.LayerNorm(cfg.n_embd)        \n","        self.rnn   = nn.GRU(cfg.n_embd, cfg.Eh, batch_first=True) if cfg.is_rnn else None\n","        self.cfg   = cfg\n","\n","    def forward(self, x):    \n","        x = self.ln(x)                           # !!??\n","        if self.rnn is None:\n","            if self.cfg.is_max:                  # (B,2*E)\n","                x =torch.cat([x.mean(dim=1), x.amax(dim=1)], dim=1)\n","            else:\n","                x = torch.mean(x, dim=1)         # (B,E) \n","        else:             \n","            _, x = self.rnn(x)                   # (1,B,Eh) integrate all pulses            \n","            x = torch.squeeze(x, dim=0)          # (B,Eh)                        \n","        return x\n","#-------------------------------------------------------------------------------\n","\n","class Model(nn.Module):\n","    def __init__(self,cfg, doms):\n","        \"\"\" \n","        Prediction model (common for regressor and classifier) \n","        \"\"\"\n","        super().__init__()    \n","        self.cfg = copy.deepcopy(cfg)           \n","        self.gen = FeatureGenerator(cfg, doms)        \n","        if cfg.tri == 0:\n","            self.att = Transformer(cfg)\n","        else:\n","            self.atts= nn.ModuleList([Transformer(cfg) for _ in range(cfg.tri)])         \n","        self.sum = Integrator(cfg)\n","         \n","        self.is_agg = cfg.is_agg\n","        if cfg.is_rnn:\n","            Ein  = cfg.Eh\n","        else: \n","            Ein  = 2*cfg.n_embd  if cfg.is_max else cfg.n_embd\n","            if self.cfg.tri > 0:\n","                Ein *= self.cfg.tri\n","        if cfg.is_agg:\n","            Ein += cfg.AF\n","        Eout = 3 if cfg.is_reg else cfg.nums[0]*cfg.nums[1]  \n","\n","        self.mlp = MLP(dict(input=Ein, hidden=cfg.Hout, output=Eout))        \n","\n","    def forward(self, SENSOR_ID, FEAT, AGG, Y):    \n","        if CFG.frozen: torch.set_grad_enabled(False) \n","\n","        x = self.gen(SENSOR_ID, FEAT)            # (B,T,E)\n","        if self.cfg.tri == 0:\n","            x = self.att(x)                      # (B,T,E)\n","            x = self.sum(x)                      # (B,E)           \n","        else:\n","            res = []\n","            for att in self.atts:\n","                res.append( self.sum (att(x)) )\n","            x = torch.cat(res, dim=-1)           # (B,E*tri)\n","        \n","        if CFG.frozen and self.training: torch.set_grad_enabled(True) \n","\n","        if self.is_agg:\n","            AGG = torch.clip(AGG, -10, 10)       # на всякий случай\n","            x = torch.cat([x, AGG], dim=1)       # (B, Eh+AF) or (B, E+AF)\n","\n","        x = self.mlp(x)                          # (B,...)        \n","        return x\n","\n","#-------------------------------------------------------------------------------\n","\n","class Regression(nn.Module):\n","    def __init__(self,cfg, doms):\n","        \"\"\" \n","        Regression model - predict three direction components\n","        \"\"\"\n","        super(Regression, self).__init__()              \n","        self.model = Model(cfg, doms)          \n","\n","    def forward(self, SENSOR_ID, FEAT, AGG, Y, eps=1e-8):    \n","        x = self.model(SENSOR_ID, FEAT, AGG, Y) # (B,3)\n","\n","        if   CFG.loss == 'cos':\n","            kappa = torch.norm(x, dim=1, keepdim=True).clip(eps)\n","            y = x / kappa                          \n","            cos = (y*Y).sum(dim=1).mean()\n","            loss = ( 1 - cos.mean() ) + CFG.ka_reg * (x*x).sum(dim=1).mean()  #  * B / CFG.batch_size  # !!!???\n","        elif CFG.loss == 'prod':\n","            loss = -((x*Y).sum(dim=1)).mean() + CFG.ka_reg * (x*x).sum(dim=1).mean()   \n","        elif CFG.loss == 'vMF':\n","            kappa = torch.norm(x, dim=1, keepdim=True).clip(eps)\n","            logC  = -kappa + torch.log( ( kappa+eps )/( 1-torch.exp(-2*kappa)+2*eps ) )\n","            loss =  -( (x*Y).sum(dim=1) + logC ).mean() \n","        elif CFG.loss == 'k2':             \n","            loss = -((x*Y).sum(dim=1)).mean() + 0.5 * (x*x).sum(dim=1).mean() # + 1e-3*x[:,2].mean()\n","        elif CFG.loss == 'azze':\n","            kappa = torch.norm(x, dim=1, keepdim=True)\n","            y = x / kappa.clip(eps)              \n","            r2y   =  y[:,0]*y[:,0] + y[:,1]*y[:,1] \n","            r2Y   =  Y[:,0]*Y[:,0] + Y[:,1]*Y[:,1]\n","            ryY   =  torch.sqrt(r2y*r2Y)\n","\n","            cos  = (y*Y).sum(dim=1)\n","            cosA = (y[:,0]*Y[:,0] + y[:,1]*Y[:,1]) / ryY.clip(eps)                \n","            cosZ = y[:,2]*Y[:,2] + ryY      # cos(theta_y-theta_Y)\n","\n","            loss = 1 - cos.mean()               \\\n","                 + CFG.az_reg * (1-cosA.mean()) \\\n","                 + CFG.ze_reg * (1-cosZ.mean()) \\\n","                 + CFG.ka_reg * (x*x).sum(dim=1).mean()\n","\n","        with torch.no_grad():                \n","            kappa = torch.norm(x.detach(), dim=1, keepdim=True).clip(eps)                        \n","            y = x.detach() / kappa\n","            ang_err, az_err, ze_err = Phys.angle_errors(y, Y, eps=eps)            \n","        return loss, y.detach(), ang_err.detach(), az_err.detach(), torch.abs(ze_err.detach()),  kappa.detach()\n","\n","#-------------------------------------------------------------------------------\n","\n","class Classifier(nn.Module):\n","    def __init__(self, cfg, doms):\n","        \"\"\" \n","        Classification model - predicting the direction number\n","        \"\"\"\n","        super().__init__()               \n","        self.model = Model(cfg, doms)      \n","        self.cfg   = cfg    \n","\n","    def forward(self, SENSOR_ID, FEAT, AGG, Y, eps=1e-8):    \n","        x = self.model(SENSOR_ID, FEAT, AGG, Y) # (B,3)\n","\n","        kappa = torch.square(x).mean()\n","        az_true, ze_true = Phys.vector2angles(Y)\n","        id_true = Phys.angles2index(az_true, ze_true, n_az=self.cfg.nums[0], n_ze=self.cfg.nums[1])\n","        CE_loss = nn.CrossEntropyLoss()\n","        loss = CE_loss(x, id_true) + CFG.ka_reg * kappa\n","        pred = x.detach().argmax(axis=1)\n","        az_pred, ze_pred = Phys.index2angles(pred, n_az=self.cfg.nums[0], n_ze=self.cfg.nums[1])\n","        y = Phys.angles2vector(az_pred, ze_pred)        \n","        ang_err, az_err, ze_err = Phys.angle_errors(y, Y, eps=eps)            \n","        return loss, y.detach(), ang_err.detach(), az_err.detach(), torch.abs(ze_err.detach()), torch.sqrt(kappa.detach())\n","\n","#-------------------------------------------------------------------------------\n","\n","class Phys:\n","    \"\"\"\n","    General helper methods for working with  geometry\n","    \"\"\"\n","    def angle_errors(n1, n2, eps=1e-8):\n","        \"\"\" \n","        Calculate angles between two unit (!!!)  vectors:: n1,n2: (B,3) \n","        return: (B,) \n","        \"\"\"\n","        with torch.no_grad():\n","            cos = (n1*n2).sum(axis=1)                     # angles between vectors\n","            angle_err = torch.arccos( cos.clip(-1,1) )    \n","        \n","            r1   =  n1[:,0]*n1[:,0] + n1[:,1]*n1[:,1]    # angles between vectors in (x,y)    \n","            r2   =  n2[:,0]*n2[:,0] + n2[:,1]*n2[:,1]\n","            norm = torch.sqrt(r1*r2)\n","            cosX = (n1[:,0]*n2[:,0] + n1[:,1]*n2[:,1]) / norm.clip(eps)    \n","            azimuth_err = torch.arccos( cosX.clip(-1,1) )\n","                                \n","            zerros = norm < eps                            # azimuth angle not defined\n","            azimuth_err[zerros] = torch.rand((len(n1[zerros]),), device=n1.device)*torch.pi\n","    \n","            zenith1  = torch.arccos( n1[:,2].clip(-1,1) )\n","            zenith2  = torch.arccos( n2[:,2].clip(-1,1) )\n","            zenith_err = zenith2 - zenith1    \n","        \n","        return angle_err, azimuth_err, zenith_err\n","\n","    def vector2angles(n, eps=1e-8):\n","        \"\"\"  \n","        Get spherical angles of vector n: (B,3) \n","        \"\"\"                \n","        n = n / torch.norm(n, dim=1, keepdim=True).clip(eps)\n","                                \n","        azimuth = torch.arctan2( n[:,1],  n[:,0])    \n","        azimuth[azimuth < 0] += 2*torch.pi\n","                                \n","        zenith = torch.arccos( n[:,2].clip(-1,1) )                                \n","    \n","        return azimuth, zenith\n","\n","    def angles2vector(azimuth, zenith):\n","        \"\"\" \n","        Add unit vector components from (azimuth,zenith) to the DataFrame df \n","        \"\"\"\n","        nx = (torch.sin(zenith) * torch.cos(azimuth)).view(-1,1)\n","        ny = (torch.sin(zenith) * torch.sin(azimuth)).view(-1,1)\n","        nz = torch.cos(zenith).view(-1,1)\n","        return torch.cat([nx,ny,nz], dim=1)\n","\n","    def angles2index(azimuth, zenith, n_az, n_ze):\n","        \"\"\" \n","        Convert angles to direction number.\n","        naz, n_ze - number of bins for each corner\n","        \"\"\"\n","        az = torch.floor(n_az * azimuth / (2*np.pi)).clip(0,n_az-1)\n","        ze = torch.floor(n_ze * (torch.cos(zenith)+1)/2).clip(0,n_az-1)\n","        return (az*n_ze + ze).to(torch.long)\n","\n","    def index2angles(index, n_az, n_ze):\n","        \"\"\" \n","        Transfer the direction number to angles. \n","        naz, n_ze - number of bins for each corner\n","        \"\"\"\n","        az = (index // n_ze)  \n","        ze = torch.arccos( (2*((index - az*n_ze)/n_ze) - 1).clip(-1,1) )\n","        az = az * (2*torch.pi) / n_az\n","        return az, ze        \n","\n","#===============================================================================\n","\n","def load_model(fname, doms, verbose=True):\n","    \"\"\"\n","    Load model from pytorch pt-file\n","    \"\"\"\n","    state = torch.load(fname)\n","    if 'is_fin'    not in state['config']: state['config']['is_fin']    = 0    \n","    if 'tri'       not in state['config']: state['config']['tri']       = 0\n","    if 'res'       not in state['config']: state['config']['res']       = 1\n","    if 'is_max'    not in state['config']: state['config']['is_max']    = 0\n","    if 'is_rho'    not in state['config']: state['config']['is_rho']    = 0    \n","    if 'is_pnt'    not in state['config']: state['config']['is_pnt']    = 0        \n","    if 'n_embd'    not in state['config']: state['config']['n_embd']    =  state['config']['E']\n","    if 'n_head'    not in state['config']: state['config']['n_head']    =  8\n","    if 'causal'    not in state['config']: state['config']['causal']    =  False    \n","    if 'drop_attn' not in state['config']: state['config']['drop_attn'] =  0    \n","    if 'drop_mlp'  not in state['config']: state['config']['drop_mlp']  =  0    \n","    if 'hidden'    not in state['config']: state['config']['hidden']    =  4    \n","    if 'fun'       not in state['config']: state['config']['fun']       =  'gelu'     \n","    if 'poly'      not in state['config']: state['config']['poly']      = False\n","\n","    if verbose: print(state['config'])    \n","    class ModelConfig(object): pass     \n","    cfg = ModelConfig()            \n","    for key in state['config']:\n","        setattr(cfg, key, state['config'][key])\n","    #cfg.res = 2         \n","    if cfg.is_reg:\n","        model = Regression(cfg, doms)\n","    else:\n","        model = Classifier(cfg, doms)\n","    model.load_state_dict(state['model'])     \n","\n","    history     = state.get('history',[])\n","    labels      = state.get('labels', [])\n","    checks      = state.get('checks', [])\n","\n","    CFG.samples = history[-1][0] if len(history) else 0       \n","    CFG.steps   = state.get('steps', 0)\n","    CFG.last    = state.get('last',  0)\n","    CFG.score   = state.get('score', 100)\n","    \n","    return model, history, labels, checks\n","\n","#===============================================================================\n","\n","def model_state(model):\n","    \"\"\"\n","    Model state for loading\n","    \"\"\"\n","    cfg = model.model.cfg if model.model is not None else model.cfg\n","    state = {'info':      \"IceCube at\", \n","             'date':      datetime.datetime.now(),   \n","             'config':    dict([(k,v) for k,v in cfg.__dict__.items() if not k.startswith(\"__\")]),\n","             'model' :    model.state_dict(),        \n","             'optimizer': optimizer.state_dict(),    \n","             'history':   history,\n","             'labels':    labels,\n","             'checks':    checks,\n","             'score':     CFG.score,\n","             'steps':     CFG.steps,\n","             'samples':   CFG.samples,\n","             }    \n","    return state\n","\n","#-------------------------------------------------------------------------------\n","def save_model(model, fname):              \n","    state = model_state(model)  \n","    torch.save(state, fname)\n","\n","def save_best_model(model, score, folder=\"/content/drive/MyDrive/IceCube/\"):              \n","    cfg = model.model.cfg if model.model is not None else model.cfg\n","    CFG.last = CFG.samples    \n","    CFG.score= round(score, 5)        \n","    CFG.best = f'att_{score:.4f}_D{DATA_KIND}_A{ModelCFG.arch}_F{ModelCFG.F}_AF{ModelCFG.AF}_E{ModelCFG.n_embd}_L{cfg.L}_Eh{ModelCFG.Eh}_Hout{ModelCFG.Hout}_T{CFG.T_max}'\n","    state = model_state(model)  \n","    torch.save(state, folder+CFG.best+\".pt\")\n","\n","def save_model_checkpoint(model,  error_val, error_trn, folder=\"/content/drive/MyDrive/IceCube/checkpoints/\"):                \n","    state = model_state(model)  \n","    now = datetime.datetime.now().strftime(\"%m-%d %H:%M:%S\")\n","    fname = f'{now} er_val_{error_val:.4f}_trn_{error_trn:.4f} az_{history[-1][3]:.3f} ze_{history[-1][4]:.3f} ka_{history[-1][-4]:.3f}.pt'    \n","    torch.save(state, folder+fname)\n","\n","#===============================================================================\n","\n","def load_model_old(fname, model):\n","    CFG.best = fname  \n","    state = torch.load('/content/drive/MyDrive/IceCube/'+CFG.best)       # /best\n","    print(state['config'])\n","    #for k in state['model'].keys(): print(k)\n","    model.load_state_dict(state['model'])     \n","    CFG.samples = state['history'][-1][0] if len(state['history']) else 0       \n","    CFG.steps   = state['steps']          if 'steps' in state      else 0\n","    CFG.last    = state['config']['last']\n","    CFG.score   = state['score']\n","    history     = state['history']\n","    labels      = state['labels'] if 'labels' in state else []\n","    checks      = state['checks'] if 'checks' in state else []    \n","    print(state['labels'])\n","    return history, labels, checks\n"]},{"cell_type":"markdown","metadata":{"id":"2XUBtvdqezLN"},"source":["## Model Create"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1272,"status":"ok","timestamp":1681995541416,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"},"user_tz":-180},"id":"0G1fVltddFTo","outputId":"a7ef37e7-26b3-412f-98a7-65a9dffe81ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["  4.9m[+122.0s]  3.733Gb > T_max:512, AF:48, frozen:False, loss:azze, ka_reg:0, ze_reg:0, az_reg:0, lr:0.001, batch_size:128, batch_max:256, params:0, samples:0, steps:0, last:0, score:100, device:cuda, plt:<function CFG.plt at 0x7f8d1c6a5790>, \n","cuda\n"]},{"output_type":"display_data","data":{"text/plain":["===============================================================================================\n","Layer (type:depth-idx)                        Param #                   Trainable\n","===============================================================================================\n","Regression                                    --                        Partial\n","├─Model: 1-1                                  --                        Partial\n","│    └─FeatureGenerator: 2-1                  --                        Partial\n","│    │    └─Embedding: 3-1                    (30,960)                  False\n","│    │    └─MLP: 3-2                          --                        True\n","│    │    │    └─Linear: 4-1                  2,560                     True\n","│    │    │    └─Linear: 4-2                  32,896                    True\n","│    └─Transformer: 2-2                       --                        True\n","│    │    └─ModuleList: 3-3                   --                        True\n","│    │    │    └─TransformerBlock: 4-3        2                         True\n","│    │    │    │    └─LayerNorm: 5-1          256                       True\n","│    │    │    │    └─SelfAttention: 5-2      66,048                    True\n","│    │    │    │    └─LayerNorm: 5-3          256                       True\n","│    │    │    │    └─MLP: 5-4                131,712                   True\n","│    │    │    └─TransformerBlock: 4-4        2                         True\n","│    │    │    │    └─LayerNorm: 5-5          256                       True\n","│    │    │    │    └─SelfAttention: 5-6      66,048                    True\n","│    │    │    │    └─LayerNorm: 5-7          256                       True\n","│    │    │    │    └─MLP: 5-8                131,712                   True\n","│    │    │    └─TransformerBlock: 4-5        2                         True\n","│    │    │    │    └─LayerNorm: 5-9          256                       True\n","│    │    │    │    └─SelfAttention: 5-10     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-11         256                       True\n","│    │    │    │    └─MLP: 5-12               131,712                   True\n","│    │    │    └─TransformerBlock: 4-6        2                         True\n","│    │    │    │    └─LayerNorm: 5-13         256                       True\n","│    │    │    │    └─SelfAttention: 5-14     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-15         256                       True\n","│    │    │    │    └─MLP: 5-16               131,712                   True\n","│    │    │    └─TransformerBlock: 4-7        2                         True\n","│    │    │    │    └─LayerNorm: 5-17         256                       True\n","│    │    │    │    └─SelfAttention: 5-18     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-19         256                       True\n","│    │    │    │    └─MLP: 5-20               131,712                   True\n","│    │    │    └─TransformerBlock: 4-8        2                         True\n","│    │    │    │    └─LayerNorm: 5-21         256                       True\n","│    │    │    │    └─SelfAttention: 5-22     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-23         256                       True\n","│    │    │    │    └─MLP: 5-24               131,712                   True\n","│    │    │    └─TransformerBlock: 4-9        2                         True\n","│    │    │    │    └─LayerNorm: 5-25         256                       True\n","│    │    │    │    └─SelfAttention: 5-26     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-27         256                       True\n","│    │    │    │    └─MLP: 5-28               131,712                   True\n","│    │    │    └─TransformerBlock: 4-10       2                         True\n","│    │    │    │    └─LayerNorm: 5-29         256                       True\n","│    │    │    │    └─SelfAttention: 5-30     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-31         256                       True\n","│    │    │    │    └─MLP: 5-32               131,712                   True\n","│    │    │    └─TransformerBlock: 4-11       2                         True\n","│    │    │    │    └─LayerNorm: 5-33         256                       True\n","│    │    │    │    └─SelfAttention: 5-34     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-35         256                       True\n","│    │    │    │    └─MLP: 5-36               131,712                   True\n","│    │    │    └─TransformerBlock: 4-12       2                         True\n","│    │    │    │    └─LayerNorm: 5-37         256                       True\n","│    │    │    │    └─SelfAttention: 5-38     66,048                    True\n","│    │    │    │    └─LayerNorm: 5-39         256                       True\n","│    │    │    │    └─MLP: 5-40               131,712                   True\n","│    │    └─Dropout: 3-4                      --                        --\n","│    │    └─LayerNorm: 3-5                    256                       True\n","│    └─Integrator: 2-3                        --                        True\n","│    │    └─LayerNorm: 3-6                    256                       True\n","│    │    └─GRU: 3-7                          296,448                   True\n","│    └─MLP: 2-4                               --                        True\n","│    │    └─Linear: 3-8                       624,640                   True\n","│    │    └─Linear: 3-9                       6,147                     True\n","===============================================================================================\n","Total params: 2,976,903\n","Trainable params: 2,945,943\n","Non-trainable params: 30,960\n","==============================================================================================="]},"metadata":{}}],"source":["class ModelCFG:    \n","    AF    =  24*2       # event features \n","    F     =   3         # pulse features> 3:(aux, q, t) or 2:(q, t) next add 4:(x,y,z,core,a)\n","    SE    =   4         # DOM embedding dim (if is_cat == 0 equal E)\n","    \n","    L     = 10          # transformer layers\n","    Eh    = 256         # embedding after rnn (if not or mean\n","    Hin   = 256         # hidden layer in feature generator     (4+8=12) -> 32 -> 64\n","    Hout  = 2048        # neurons in hidden layer of output MLP  64 -> 256 -> 3    \n","\n","    data     = DATA_KIND\n","    arch     = \"\"    \n","    is_max   = 0         # add max to mean during aggregation\n","    is_agg   = 1         # use aggregated event features\n","    is_emb   = 0         # add sensor embedding\n","    is_abs   = 1         # add absorption\n","    is_rho   = 1         # add r = (x**2+y**2)**0.5    \n","    \n","    is_fin   = 0         # add aux0 agg features to every pulse\n","    is_cat   = 1         # sensor embedding attach to features    \n","    is_rnn   = 1         # use RNN output    \n","    tri      = 0         # use multiple parallel transformers    \n","    T_max    =10\n","\n","    is_reg   = 1         # regression model otherwise classifier    \n","\n","    nums     = [180, 60] # number of partitions of azimuth and zenith angles (classifier)\n","    #------------------------------- Transformer:    \n","    n_embd:     int   = 128     # embedding dimension    \n","    n_head:     int   =  16     # number of heads in attention (divisor of n_embd)\n","    res:        int   =  2     # skip-connection (0: none, 1: single, 2: trainable)\n","\n","CFG.samples = 0      # was training samlpes\n","CFG.score   = 100    # best model error\n","history = []         # learning history\n","labels  = []         # notes in history\n","checks  = []         # chekpoints (save best model)\n","\n","LOAD_MODEL = False   # load old model\n","if LOAD_MODEL: \n","    model, history, labels, checks = load_model('/content/drive/MyDrive/IceCube-all/att_0.9986_D01_A_F3_AF48_E128_L12_Eh256_Hout2048_T256.pt', DOMS)\n","else:\n","    model = Regression(ModelCFG, DOMS)        \n","\n","info(CFG.get())  \n","CFG.params = ModelCFG.params = sum(p.numel() for p in model.parameters() if p.requires_grad) \n","\n","model = model.to(CFG.device)\n","print(CFG.device)\n","display(summary(model, col_names=[\"num_params\",\"trainable\"], depth=5))"]},{"cell_type":"markdown","metadata":{"id":"Dp8x0KKkYV89"},"source":["## Scheduler"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1681995640996,"user":{"displayName":"Steps AIData","userId":"17350950787190850792"},"user_tz":-180},"id":"RMeoy-ItYW0X","outputId":"fcdc2ce4-412f-4fbf-f199-cd5a2c6a1390"},"outputs":[{"output_type":"display_data","data":{"text/plain":["========================================================================================================================\n","Layer (type:depth-idx)                        Param #                   Trainable                 Param %\n","========================================================================================================================\n","Regression                                    --                        Partial                        --\n","├─Model: 1-1                                  --                        Partial                        --\n","│    └─FeatureGenerator: 2-1                  --                        Partial                        --\n","│    │    └─Embedding: 3-1                    (30,960)                  False                       1.04%\n","│    │    └─MLP: 3-2                          --                        True                           --\n","│    │    │    └─Linear: 4-1                  2,560                     True                        0.09%\n","│    │    │    └─Linear: 4-2                  32,896                    True                        1.11%\n","│    └─Transformer: 2-2                       --                        True                           --\n","│    │    └─ModuleList: 3-3                   --                        True                           --\n","│    │    │    └─TransformerBlock: 4-3        198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-4        198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-5        198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-6        198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-7        198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-8        198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-9        198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-10       198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-11       198,274                   True                        6.66%\n","│    │    │    └─TransformerBlock: 4-12       198,274                   True                        6.66%\n","│    │    └─Dropout: 3-4                      --                        --                             --\n","│    │    └─LayerNorm: 3-5                    256                       True                        0.01%\n","│    └─Integrator: 2-3                        --                        True                           --\n","│    │    └─LayerNorm: 3-6                    256                       True                        0.01%\n","│    │    └─GRU: 3-7                          296,448                   True                        9.96%\n","│    └─MLP: 2-4                               --                        True                           --\n","│    │    └─Linear: 3-8                       624,640                   True                       20.98%\n","│    │    └─Linear: 3-9                       6,147                     True                        0.21%\n","========================================================================================================================\n","Total params: 2,976,903\n","Trainable params: 2,945,943\n","Non-trainable params: 30,960\n","========================================================================================================================"]},"metadata":{}}],"source":["from qunet.optim import ExpScheduler, CosScheduler\n","\n","CFG.frozen     = False   \n","CFG.L_frozen   = 9\n","#labels.append([CFG.samples, CFG.score, f'unfrozen']) \n","\n","dataset_trn.set(batch_size=100,  batch_max=256,  T_max=512)\n","dataset_val.set(batch_size=200,  batch_max=512,  T_max=512)\n","\n","CFG.lr         =  1e-3\n","\n","CFG.az_reg     = 0\n","CFG.ze_reg     = 0\n","CFG.ka_reg     = 0\n","CFG.loss       = 'k2'       #'cos' vMF k2\n","\n","#labels.append([CFG.samples, CFG.score, f'ALL_512']) \n","\n","CFG.params = ModelCFG.params = sum(p.numel() for p in model.parameters() if p.requires_grad) \n","\n","display(summary(model, col_names=[\"num_params\",\"trainable\",\"params_percent\"], depth=4))\n","model.to(CFG.device)\n","\n","\n","optimizer = torch.optim.Adam(model.parameters(),  lr=CFG.lr) #  weight_decay = CFG.L2\n","scheduler = ExpScheduler(optimizer)\n","scheduler.set(lr1=None,  lr2=1e-4, samples=20e6)"]},{"cell_type":"markdown","metadata":{"id":"pzM4l9CgTCrH"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RbpkXZFdYc43"},"outputs":[],"source":["%%time\n","def fit(dataset, it=0, train=True):\n","    model.train(train)     \n","    torch.set_grad_enabled(train)\n","\n","    tot, drops, steps, beg, lst =  0, 0, 0, time.time(), time.time()\n","    scores, counts, kappas, samples = [], [], [], 0\n","    losses, errors, az_errs, ze_errs, kappas, counts = torch.zeros(0,).to(CFG.device), torch.zeros(0,).to(CFG.device), torch.zeros(0,).to(CFG.device), torch.zeros(0,).to(CFG.device), torch.zeros(0,).to(CFG.device), []\n","    #errors_all, samples_all = torch.zeros(0,).to(CFG.device), torch.zeros(0,)\n","    hist = []\n","    tm1, tm2, tm3, tm4 = 0,0,0,0\n","    for b, (EVENT_ID, SENSOR_ID, FEAT, AGG, Y, ERR) in enumerate(dataset):           \n","        samples += len(EVENT_ID)                \n","        if train and ERR is not None and ERR[0] > CFG.score*1.2:  # ???\n","            drops += len(EVENT_ID)                        \n","            continue                \n","        \n","        t = time.time()\n","        if dataset.device == 'cpu' and CFG.device != 'cpu':\n","            SENSOR_ID, FEAT, AGG, Y = SENSOR_ID.to(CFG.device), FEAT.to(CFG.device), AGG.to(CFG.device), Y.to(CFG.device)\n","        tm1 += time.time() - t\n","        \n","        t = time.time()                \n","        loss, y,  ang_err, az_err, ze_err, kappa = model(SENSOR_ID, FEAT, AGG, Y)     \n","        #errors_all = torch.cat([errors_all, ang_err])                  \n","        ang_err, az_err, ze_err, kappa = ang_err.mean(), az_err.mean(), ze_err.mean(), kappa.mean()\n","        tm2 += time.time() - t\n","\n","        t = time.time()\n","        if train:\n","            optimizer.zero_grad()   \n","            loss.backward()         \n","            optimizer.step()                     \n","            CFG.samples += len(EVENT_ID)  # !!!!\n","            CFG.steps   += 1\n","        steps += 1\n","        #samples_all = torch.cat([samples_all, torch.Tensor([CFG.samples])])                  \n","        tm3 += time.time() - t                         \n","\n","        t = time.time()\n","        losses = torch.cat([losses,  loss.detach().view(1,)])\n","        errors = torch.cat([errors,  ang_err.view(1,)])\n","        az_errs= torch.cat([az_errs, az_err.view(1,)])\n","        ze_errs= torch.cat([ze_errs, ze_err.view(1,)])\n","        kappas = torch.cat([kappas,  kappa.view(1,)])        \n","        counts.append(len(y)) \n","        hist.append(FEAT.shape)\n","        tm4 += time.time() - t\n","        \n","        if time.time() - lst > 1 or b == len(dataset)-1:\n","            lst = time.time()\n","            error = (errors.cpu().numpy()*np.array(counts)).sum() / np.sum(counts)\n","            az_err= (az_errs.cpu().numpy()*np.array(counts)).sum() / np.sum(counts)\n","            ze_err= (ze_errs.cpu().numpy()*np.array(counts)).sum() / np.sum(counts)\n","            t0 = time.time()-beg                                                                                                            # drops={100*drops/samples:.2f}% of {samples/1e6:.3f}  t={100*tm1/t0:.0f}+{100*tm2/t0:.0f}+{100*tm3/t0:.0f}+{100*tm4/t0:.0f}={100*(tm1+tm2+tm3+tm4)/t0:.0f}\n","            print(f\"\\rit:{it:4d}{'t' if train else 'v'}[{dataset.file_id:2d}]  {100*(b+1)/len(dataset):3.0f}%  loss={np.mean(losses.cpu().numpy()):.5f}  error: {error:6.4f} (az:{az_err:6.3f}, ze:{ze_err:6.3f})  ({len(FEAT):4d},{FEAT.shape[1]:4d},{FEAT.shape[2]:4d})   tm={1000*(time.time()-beg)/steps:.1f}ms/step,  {(time.time()-beg)*1e6/(60*np.sum(counts)):.2f}m/1e6,  steps={len(dataset)}\", end=\"         \")\n","\n","    error = (errors.cpu().numpy()*np.array(counts)).sum()  / np.sum(counts)\n","    az_err= (az_errs.cpu().numpy()*np.array(counts)).sum() / np.sum(counts)\n","    ze_err= (ze_errs.cpu().numpy()*np.array(counts)).sum() / np.sum(counts)\n","\n","    if False:\n","        plt.figure(figsize=(12,5), facecolor ='w')\n","        ax1 = plt.subplot(111)\n","        ax1.plot(errors.cpu().numpy(), \"-r\")\n","        ax2 = ax1.twinx()\n","        ax2.plot(np.array(hist).transpose()[1], \"-b\")\n","        #ax3 = ax1.twinx()\n","        #ax3.plot(np.array(hist).transpose()[0])\n","        plt.show()\n","\n","    #return errors_all.cpu(), samples_all, error, az_err, ze_err, 0, kappas.mean().cpu().item(), (time.time()-beg)*1e6/(60*np.sum(counts))\n","    return error, az_err, ze_err, 0, kappas.mean().cpu().item(), (time.time()-beg)*1e6/(60*np.sum(counts)), samples\n","\n","#-------------------------------------------------------------------------------\n","\n","if True:   \n","    info(\"Good luck!\")     \n","    error_trn, error_val, last_best,  beg, tm_trn, tm_val = 1.5, 3.1415, 0, time.time(), 0, 0\n","    kappa_val, kappa_trn, loss_trn, loss_val = 0, 0, 0,0\n","    az_err_val, ze_err_val = 0, 0\n","    CFG.lr = scheduler.get_lr()\n","    if len(history) > 0:\n","        error_trn, error_val, az_err_val, ze_err_val = history[-1][1], history[-1][2], history[-1][3], history[-1][4]         \n","        kappa_val, kappa_trn = history[-1][6],  history[-1][7]\n","        \n","    n_iters = 20\n","    \n","    if False:\n","        dataset_val.reset()        \n","        _, _, error_val, az_err_val, ze_err_val, loss_val, kappa_val, tm_val, samples_val = fit(dataset_val, 0, train=False)\n","        print()\n","\n","    for it in tqdm( range(1, n_iters + 1)  ):                                               \n","        dataset_trn.reset()            # ?           \n","        CFG.lr = scheduler.get_lr()\n","        error_trn, az_err_trn, ze_err_trn, loss_trn, kappa_trn, tm_trn, samples_trn = fit(dataset_trn, it, train=True)        \n","        \n","        if it % 1 == 0 or it == n_iters:   # в конце валидация           \n","            dataset_val.reset()            # ?               \n","            error_val, az_err_val, ze_err_val, loss_val, kappa_val, tm_val, samples_val = fit(dataset_val, it, train=False)                                    \n","\n","        history.append( (CFG.samples, error_trn, error_val, az_err_val, ze_err_val, CFG.steps, kappa_trn, kappa_val, CFG.lr, tm_trn, tm_val) )        \n","        save_model_checkpoint(model, error_val, error_trn, folder=\"/content/drive/MyDrive/IceCube-all/checkpoints/\")\n","\n","        if error_val < CFG.score:                                \n","            save_best_model(model, error_val, folder=\"/content/drive/MyDrive/IceCube-all/\")\n","            CFG.score= round(error_val, 5)\n","            checks.append((CFG.samples, error_val))\n","            last_best  = it             \n","\n","        if  it % 2  == 0 or it == n_iters:        \n","            plot(history, checks, labels, xmin=-100, ymin=0.996, ymax=1.006, ticks=11, info=\"\")     \n"," \n","        if it % 1 == 0:                      # колбасит из-за новых батчей или lr?        \n","            dataset_trn.load_next() # !!!  \n","\n","        scheduler.step(samples_trn)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"143sRHGkXCln-Z4nZ7yQk_M_kNHGRK7On","timestamp":1681969600574},{"file_id":"1jZvOHHIWg9j60x1dGzcKy2h9oNcAArDc","timestamp":1681395049681}],"mount_file_id":"1mNqKHpx_wz1i0WDVBAuApQZQqnym6xAd","authorship_tag":"ABX9TyNfoy7VvaTh8K8Rr84aAz2n"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a11742c33335441db0ffdfa63a290a94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86ee357809fd4fb483bc5903628412bf","IPY_MODEL_96ac6e701ad1476fafc963be02dd1117","IPY_MODEL_63ecdd23e13248c58f2378894a88e079"],"layout":"IPY_MODEL_d152c463d6e44a369ae22988998b6c18"}},"86ee357809fd4fb483bc5903628412bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57ecaf1bfe3f492e83e343c4fe318de5","placeholder":"​","style":"IPY_MODEL_dd3a1500c47145cabec6652cf62e1a77","value":"100%"}},"96ac6e701ad1476fafc963be02dd1117":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_272870d52eab467ea0474f6986f9ae39","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f28328d5c91458ab4bdcd054a5fa04b","value":1}},"63ecdd23e13248c58f2378894a88e079":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b4718a01b0b4d249ef6291e0c98849a","placeholder":"​","style":"IPY_MODEL_6840455cfa0946e4944b22e42447ffad","value":" 1/1 [00:14&lt;00:00, 14.72s/it]"}},"d152c463d6e44a369ae22988998b6c18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57ecaf1bfe3f492e83e343c4fe318de5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd3a1500c47145cabec6652cf62e1a77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"272870d52eab467ea0474f6986f9ae39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f28328d5c91458ab4bdcd054a5fa04b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b4718a01b0b4d249ef6291e0c98849a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6840455cfa0946e4944b22e42447ffad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c3e02e9d6644787ab18858fe720417b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a5724f18f454b779649d31a1841a901","IPY_MODEL_9b11f592bf0b436e8b94bb80d7ec1449","IPY_MODEL_8a30220b696a4d06b25f5e9d5dde77db"],"layout":"IPY_MODEL_9fe82fc0ad9340d385b6b504dc3c1305"}},"3a5724f18f454b779649d31a1841a901":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b01405dd2ce148e8bd7936d954dab621","placeholder":"​","style":"IPY_MODEL_67a3ee80386c42a4a3f155f3a0791981","value":"100%"}},"9b11f592bf0b436e8b94bb80d7ec1449":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c30a7c4c4dc4229bec4ae4e1a118374","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c45483718544434db6b97b4e1fd869ab","value":1}},"8a30220b696a4d06b25f5e9d5dde77db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3b98662e36f42b88eeef3f0a82a1115","placeholder":"​","style":"IPY_MODEL_4b7392def50a4b4bad7fef924384df3c","value":" 1/1 [00:15&lt;00:00, 15.86s/it]"}},"9fe82fc0ad9340d385b6b504dc3c1305":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b01405dd2ce148e8bd7936d954dab621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67a3ee80386c42a4a3f155f3a0791981":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c30a7c4c4dc4229bec4ae4e1a118374":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c45483718544434db6b97b4e1fd869ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3b98662e36f42b88eeef3f0a82a1115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b7392def50a4b4bad7fef924384df3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}