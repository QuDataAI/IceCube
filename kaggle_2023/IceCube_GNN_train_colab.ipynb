{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9YlFEAy4VFa"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6eyRld15fmE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZKFICusAibH"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HkX9Smj_8iO"
      },
      "outputs": [],
      "source": [
        "#@title Load data\n",
        "\n",
        "!rm -r content\n",
        "!rm -r cache\n",
        "!rm -r /content/icecube-neutrinos-in-deep-ice\n",
        "\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/work/projects/icecube/datasets/icecube-neutrinos-in-deep-ice'\n",
        "\n",
        "!mkdir icecube-neutrinos-in-deep-ice/\n",
        "!mkdir icecube-neutrinos-in-deep-ice/train\n",
        "!mkdir icecube-neutrinos-in-deep-ice/train_meta\n",
        "\n",
        "!cp {DATASET_PATH}/sensor_geometry.csv icecube-neutrinos-in-deep-ice/\n",
        "\n",
        "!unzip {DATASET_PATH}/train_meta_splitted.zip \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtWXbwOk5lOK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#@title Install modules\n",
        "\n",
        "!rm  -r software\n",
        "!mkdir software/\n",
        "!mkdir software/graphnet\n",
        "\n",
        "!unzip /content/drive/MyDrive/work/projects/icecube/libs/graphnet-main-20230216.zip -d software/graphnet\n",
        "\n",
        "!pip install -q wandb\n",
        "!pip install -q polars\n",
        "!pip install -q torchinfo\n",
        "!pip install -q colorlog>=6.6\n",
        "!pip install -q ruamel.yaml\n",
        "!pip install -q torch==1.11+cu115 --find-links https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -q torch-cluster==1.6.0 -f https://data.pyg.org/whl/torch-1.11.0+cu115.html\n",
        "!pip install -q torch-scatter==2.0.9 -f https://data.pyg.org/whl/torch-1.11.0+cu115.html\n",
        "!pip install -q torch-sparse==0.6.13 -f https://data.pyg.org/whl/torch-1.11.0+cu115.html\n",
        "!pip install -q pytorch-lightning>=1.6\n",
        "!pip install -q \"awkward>=1.8,<2.0\"\n",
        "!pip install -q torch_geometric==2.0.4\n",
        "!pip install -q dill\n",
        "#!pip install -q cudf-cu11==22.12.0 --extra-index-url=https://pypi.nvidia.com # last vrsion depends on new protobuf with conflicts with colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4STtt0Iz7EIX"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbLSz2Gh4Ty2"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "  MODE          = 'train' # test\n",
        "  EXP_ID        = 73\n",
        "  EXP_COMMENT   = \"classific_24_bins\" # l5_post_mlp336_256_256 l5_post_mlp336_256_tr_l4_h4_f512\n",
        "  RESUME        = False\n",
        "  RESUME_MODEL  = '/content/drive/MyDrive/work/projects/icecube/models/ice_gnn_v4_exp_73_classific_24_bins/model_exp_73_classific_24_bins_last.pt'\n",
        "\n",
        "  def to_dict(): return { v:m for v, m in vars(CFG).items() if not (v.startswith('_')  or callable(m))} \n",
        "\n",
        "CFG.REMOTE_DATASET_PATH    = '/content/drive/MyDrive/work/projects/icecube/datasets/icecube-neutrinos-in-deep-ice'\n",
        "CFG.DATASET_PATH           = 'icecube-neutrinos-in-deep-ice'\n",
        "CFG.INPUT_DATA_PATH        = f'{CFG.REMOTE_DATASET_PATH}/{CFG.MODE}'\n",
        "CFG.GEOMETRY_TABLE         = f'{CFG.DATASET_PATH}/sensor_geometry.csv'\n",
        "CFG.SCATTER_ABSORT_TABLE   = f'{CFG.REMOTE_DATASET_PATH}/scattering_and_absorption.csv'\n",
        "CFG.DOMS_EFF_TABLE         = f'{CFG.REMOTE_DATASET_PATH}/doms_eff.csv'\n",
        "CFG.META_PATH              = f'/content/content/icecube-neutrinos-in-deep-ice/{CFG.MODE}_meta/'\n",
        "CFG.BATCH_RANGE            = (1,658)\n",
        "CFG.VAL_BATCH              = 659\n",
        "CFG.VAL_EVENTS             = 100000\n",
        "CFG.MAX_PULSES_PER_EVENT   = 1000\n",
        "CFG.CACHE_DIR              = 'cache'\n",
        "CFG.WANDBAPIKEY            = '****'\n",
        "CFG.USE_WANDB              = False\n",
        "CFG.LOADER                 = 'pl'  # pl,pd,cudf\n",
        "CFG.SAMPLE_FILTER          = False\n",
        "CFG.ANGLES                 = 'az,ze'  # az,ze/az/ze\n",
        "CFG.ZENITH_RANGE           = None # (0.0, math.pi/2.0) # (math.pi/2.0, math.pi) # None\n",
        "CFG.FROZEN                 = False\n",
        "CFG.UNFOROZEN_LAYERS       = []\n",
        "\n",
        "CFG.CHECKPOINTS_PATH = f\"/content/drive/MyDrive/work/projects/icecube/models/ice_gnn_v4_exp_{CFG.EXP_ID}_{CFG.EXP_COMMENT}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygSZnS3S7UwH"
      },
      "source": [
        "# Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YssG2UmP2pZ5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title helpers\n",
        "\n",
        "# Append to PATH\n",
        "import sys\n",
        "import gc\n",
        "sys.path.append('software/graphnet/src')\n",
        "\n",
        "import random\n",
        "import pyarrow.parquet as pq\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import sqlalchemy\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.optim.adam import Adam\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import getfullargspec\n",
        "import shutil\n",
        "from os import path\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import Batch, Data\n",
        "from torch.utils.data import Subset\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from scipy.interpolate import interp1d                \n",
        "import polars as pl\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "sensors_data = None\n",
        "\n",
        "if CFG.LOADER == 'cudf':\n",
        "    import cudf\n",
        "\n",
        "if CFG.MODE=='train':\n",
        "    from torchinfo import summary\n",
        "\n",
        "if CFG.USE_WANDB:\n",
        "    import wandb\n",
        "\n",
        "    def wandb_init():\n",
        "        wandb.login(key=CFG.WANDBAPIKEY)\n",
        "        wandb.init(\n",
        "            # set the wandb project where this run will be logged\n",
        "            project=\"icecube\",\n",
        "            name=f\"{CFG.EXP_ID}_{CFG.EXP_COMMENT}\",\n",
        "            config=CFG.TRAIN_CFG,\n",
        "            #resume=\"must\"\n",
        "        )\n",
        "\n",
        "\n",
        "def get_sensors(sensor_features):\n",
        "    \"\"\" Get sensor positions \"\"\"            \n",
        "    df = pd.read_csv(CFG.GEOMETRY_TABLE)      \n",
        "    df['line_id'] = df.sensor_id // 60 + 1                 # string id\n",
        "    df['core']    = (df.line_id > 78).astype(np.float32)   # sensor from DeepCore\n",
        "    df.x = df.x.astype(np.float32)              # distances in kilometers\n",
        "    df.y = df.y.astype(np.float32)\n",
        "    df.z = df.z.astype(np.float32)    \n",
        "    \n",
        "    phys = pd.read_csv(CFG.SCATTER_ABSORT_TABLE)\n",
        "    phys.z = (phys.z).astype(np.float32)\n",
        "    phys.a = (phys.a * 1e-3).astype(np.float32)\n",
        "    phys.b = (phys.b * 1e-2).astype(np.float32)\n",
        "    interp_scatter = interp1d(phys.z, phys.a)\n",
        "    interp_absort  = interp1d(phys.z, phys.b)\n",
        "    df['sc']  = interp_scatter(df.z)\n",
        "    df['abs'] = interp_absort(df.z)\n",
        "    df['r']   = np.sqrt(df.x**2 + df.y**2)*1e-3\n",
        "\n",
        "    eff = pd.read_csv(CFG.DOMS_EFF_TABLE)\n",
        "    df['eff'] = eff.astype(np.float32)\n",
        "\n",
        "    sensors_tensor = torch.tensor(df[sensor_features].values, dtype=torch.float32, device=device)\n",
        "\n",
        "    sensors_data = torch.nn.Embedding(5160, len(sensor_features), device=device, _weight=sensors_tensor).requires_grad_(False)\n",
        "\n",
        "    return sensors_data\n",
        "\n",
        "def split_meta_data():\n",
        "    if not path.isdir(CFG.META_PATH):\n",
        "        os.makedirs(CFG.META_PATH, exist_ok=True)\n",
        "    meta_data_iter = pq.ParquetFile(CFG.META_TABLE).iter_batches(batch_size = 200_000)\n",
        "    batch_ids = []\n",
        "    for meta_data_batch in tqdm(meta_data_iter):\n",
        "        meta_data_batch = meta_data_batch.to_pandas()\n",
        "        batch_id = pd.unique(meta_data_batch['batch_id'])[0]\n",
        "        if CFG.MODE == 'test':\n",
        "            if batch_id < CFG.BATCH_RANGE[0]:\n",
        "                continue            \n",
        "            if batch_id == CFG.BATCH_RANGE[1]:\n",
        "                break   \n",
        "        meta_data_batch.to_parquet(f'{CFG.META_PATH}/batch_{batch_id}_meta.parquet')\n",
        "        batch_ids.append(batch_id)        \n",
        "    batch_range = (min(batch_ids),max(batch_ids)+1)\n",
        "    return batch_range\n",
        "\n",
        "\n",
        "def load_batch(batch_id, max_events, doms_agg=False, bin_num=None):\n",
        "    reindex = False\n",
        "\n",
        "    if CFG.MODE == 'submit':\n",
        "        batch_meta_df = (\n",
        "                      pl.read_parquet(f'{CFG.META_PATH}/batch_{batch_id}_meta.parquet')\n",
        "                    ).select(['event_id','first_pulse_index','last_pulse_index']\n",
        "                    ).with_columns([\n",
        "                      pl.lit(0.0).alias('azimuth').cast(pl.Float32), \n",
        "                      pl.lit(0.0).alias('zenith').cast(pl.Float32)])\n",
        "    else:\n",
        "        batch_meta_df = (\n",
        "                      pl.read_parquet(f'{CFG.META_PATH}/batch_{batch_id}_meta.parquet')\n",
        "                    ).select(['event_id','azimuth','zenith','first_pulse_index','last_pulse_index'])\n",
        "\n",
        "    if CFG.ZENITH_RANGE:\n",
        "        batch_meta_df = batch_meta_df.filter((pl.col(\"zenith\") > CFG.ZENITH_RANGE[0]) & (pl.col(\"zenith\") <= CFG.ZENITH_RANGE[1]))\n",
        "\n",
        "      \n",
        "    batch_df = (\n",
        "                      pl.read_parquet(f'{CFG.INPUT_DATA_PATH}/batch_{batch_id}.parquet')\n",
        "                    ).select(['event_id','time','charge','auxiliary','sensor_id']\n",
        "                    ).with_columns([\n",
        "                      pl.col(\"time\").cast(pl.Float32),\n",
        "                      pl.col(\"charge\").cast(pl.Float32),\n",
        "                      #pl.lit(0.0).alias('auxiliary').cast(pl.Float32), \n",
        "                      pl.col(\"auxiliary\").cast(pl.Float32),                      \n",
        "                      pl.col(\"sensor_id\").cast(pl.Float32)])\n",
        "                    \n",
        "    if max_events:\n",
        "        batch_meta_df = batch_meta_df[:max_events]\n",
        "        batch_df = batch_df[:batch_meta_df[-1]['last_pulse_index'][0]+1]\n",
        "\n",
        "    # CFG.FILTER_BY_ENERGY = None\n",
        "    # if CFG.FILTER_BY_ENERGY:\n",
        "    #     batch_df = batch_df.filter(pl.col(\"charge\")>CFG.FILTER_BY_ENERGY)\n",
        "    #     reindex = True\n",
        "\n",
        "    reindex = True # for GRU must be sorted\n",
        "    if doms_agg:\n",
        "        batch_df = batch_df.groupby(['event_id', 'sensor_id']).agg([\n",
        "                      pl.col(\"auxiliary\").mean(),\n",
        "                      pl.col(\"charge\").sum(),\n",
        "                      pl.col(\"time\").min()\n",
        "                  ])\n",
        "    else:\n",
        "        batch_indexes = torch.tensor(batch_meta_df.select(['event_id','first_pulse_index','last_pulse_index']).to_numpy(), device=device, dtype=torch.long)\n",
        "\n",
        "    if reindex:\n",
        "        batch_df = batch_df.sort(['event_id', 'time']).with_row_count()\n",
        "        batch_indexes_df = batch_df.groupby(['event_id']).agg([\n",
        "                      pl.col(\"row_nr\").min().alias('first_pulse_index'),\n",
        "                      pl.col(\"row_nr\").max().alias('last_pulse_index'),\n",
        "                  ]).sort(['event_id'])\n",
        "        batch_indexes = torch.tensor(batch_indexes_df.to_numpy(), device=device, dtype=torch.long)\n",
        "\n",
        "    if CFG.MAX_PULSES_PER_EVENT:\n",
        "        #clip indexes\n",
        "        batch_indexes[:,2] = batch_indexes[:,2] - batch_indexes[:,1] + 1                         # pulses len\n",
        "        batch_indexes[:,2] = torch.clip(batch_indexes[:,2], min=0, max=CFG.MAX_PULSES_PER_EVENT) # clip to max\n",
        "        batch_indexes[:,2] = batch_indexes[:,1] + batch_indexes[:,2]                             # new indexes\n",
        "\n",
        "    batch_angles    = torch.tensor(batch_meta_df.select(['azimuth','zenith']).to_numpy(), device=device, dtype=torch.float32)\n",
        "\n",
        "    if CFG.ANGLES == 'az,ze':\n",
        "      batch_direcions = angles_to_vectors(batch_angles)\n",
        "    if CFG.ANGLES == 'az':\n",
        "      batch_direcions = angles_to_vectors_2D(batch_angles[:,0])\n",
        "    if CFG.ANGLES == 'ze':\n",
        "      batch_direcions = angles_to_vectors_2D(batch_angles[:,1])\n",
        "\n",
        "    batch_classes = None\n",
        "\n",
        "    if bin_num:\n",
        "        azimuth_edges, zenith_edges = build_az_ze_edges(bin_num)\n",
        "        batch_classes = angles_to_code(batch_angles, bin_num, azimuth_edges, zenith_edges)\n",
        "\n",
        "    batch_features  = torch.tensor(batch_df.select(['time','charge','auxiliary','sensor_id']).to_numpy(), device=device, dtype=torch.float32)\n",
        "    \n",
        "    return batch_indexes, batch_direcions, batch_classes, batch_features\n",
        "\n",
        "def build_dataloader(batch_id, shuffle, config, max_events=None, indexes=None):\n",
        "  print(f'build loader for batch {batch_id} with limit: {max_events}')\n",
        "  dataset = BatchDataset(batch_id, max_events, config['doms_agg'], config['bin_num'])\n",
        "  if not indexes is None:\n",
        "    dataset = Subset(dataset, indexes)\n",
        "  dataloader = DataLoader(dataset, batch_size=config['batch_size'], num_workers=0, shuffle=shuffle, collate_fn=collate_fn)\n",
        "  return dataloader\n",
        "\n",
        "def collate_fn(graphs: List[Data]) -> Batch:\n",
        "    batch = Batch.from_data_list(graphs)\n",
        "    # map x,y,z\n",
        "    batch.sensor_id = batch.sensor_id.long()\n",
        "    batch.x = torch.cat([sensors_data(batch.sensor_id), batch.x], axis=1)\n",
        "    return batch\n",
        "\n",
        "class BatchDataset(Dataset):\n",
        " \n",
        "  def __init__(self, batch_id, max_events=None, doms_agg=False, bin_num=None):\n",
        "    self.batch_indexes, self.batch_directions, self.batch_classes, self.batch_features = load_batch(batch_id, max_events, doms_agg, bin_num)\n",
        "    self.cache = {}\n",
        "    self.bin_num = bin_num\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.batch_indexes)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    cached = self.cache.get(idx)\n",
        "    if cached:\n",
        "      return cached\n",
        "    event_id, event_first_pulse, event_last_pulse = self.batch_indexes[idx] \n",
        "    event_direction = self.batch_directions[idx] \n",
        "    event_direction = event_direction.unsqueeze(0)\n",
        "    \n",
        "    x = self.batch_features[event_first_pulse:event_last_pulse,:-1]\n",
        "    sensor_id = self.batch_features[event_first_pulse:event_last_pulse,-1]\n",
        "\n",
        "    graph = Data(x=x, edge_index=None)\n",
        "    graph.n_pulses  = event_last_pulse - event_first_pulse + 1\n",
        "    graph.event_ids = event_id\n",
        "    graph.sensor_id = sensor_id\n",
        "    graph.direction = event_direction\n",
        "    if self.bin_num:\n",
        "        graph.class_id = self.batch_classes[idx].unsqueeze(0)\n",
        "    self.cache[idx] = graph\n",
        "    return graph\n",
        "\n",
        "def angles_to_vectors(angles):\n",
        "    vectors = torch.empty((angles.shape[0], 3), device=angles.device, dtype=angles.dtype)\n",
        "    zen = angles[:,1]\n",
        "    az  = angles[:,0]\n",
        "    sz = torch.sin(zen)\n",
        "    vectors[:,0] = torch.cos(az)*sz # x\n",
        "    vectors[:,1] = torch.sin(az)*sz # y\n",
        "    vectors[:,2] = torch.cos(zen)   # z\n",
        "    return vectors\n",
        "\n",
        "def vectors_to_angles(vectors):\n",
        "    vectors = vectors.clone()\n",
        "    v_squared = vectors.pow(2.0)\n",
        "        \n",
        "    ## Shortcut optimization for azimuth: calculate 2d unit vectors for x and y independent of z\n",
        "    xy_sq = torch.sum(v_squared[:, 0:2], axis=1)\n",
        "    xy_d = torch.sqrt(xy_sq)[:, None]\n",
        "        \n",
        "    vectors[:, 0:2] = torch.where(xy_d == 0, xy_d, vectors[:, 0:2]/xy_d)\n",
        "\n",
        "    ## For z, use full 3d unit vector\n",
        "    d = torch.sqrt(xy_sq + v_squared[:, 2])\n",
        "    vectors[:, 2] = torch.where(d == 0, d, vectors[:, 2]/d)\n",
        "\n",
        "    ## As mentioned by others, clip solely to avoid floating point errors, the unit vectors should already be within this range.\n",
        "    vectors =  torch.clip(vectors, -1, 1)\n",
        "\n",
        "    azimuth = torch.arccos(vectors[:, 0])\n",
        "    ## if y < 0, convert from quadrants 1 and 2 to quadrants 3 and 4\n",
        "    azimuth = torch.where(vectors[:, 1] >= 0, azimuth, 2*torch.pi - azimuth)\n",
        "    azimuth = torch.where(torch.isfinite(azimuth), azimuth, torch.tensor(0.0, dtype=azimuth.dtype, device=azimuth.device))\n",
        "\n",
        "    zenith = torch.arccos(vectors[:, 2])\n",
        "        \n",
        "    ## IMPORTANT: zenith angles are not evenly distributed, so set the error case to pi/2!\n",
        "    ## (even though x, y, z might be. It would be a fun exercise to check if random values\n",
        "    ##  for x, y, z converted to zenith angles would match the observed distribution of zenith angles in the train labels)\n",
        "    zenith = torch.where(torch.isfinite(zenith), zenith, torch.tensor(math.pi/2, dtype=zenith.dtype, device=azimuth.device))\n",
        "\n",
        "    angles = torch.stack([azimuth, zenith], axis=1)\n",
        "    return angles\n",
        "\n",
        "\n",
        "def angular_dist_score(all_true, all_pred):\n",
        "    az_true  = all_true[:,0]\n",
        "    zen_true = all_true[:,1]\n",
        "    az_pred  = all_pred[:,0]\n",
        "    zen_pred = all_pred[:,1]\n",
        "    sa1 = torch.sin(az_true)\n",
        "    ca1 = torch.cos(az_true)\n",
        "    sz1 = torch.sin(zen_true)\n",
        "    cz1 = torch.cos(zen_true)\n",
        "    sa2 = torch.sin(az_pred)\n",
        "    ca2 = torch.cos(az_pred)\n",
        "    sz2 = torch.sin(zen_pred)\n",
        "    cz2 = torch.cos(zen_pred)\n",
        "    scalar_prod = sz1*sz2*(ca1*ca2 + sa1*sa2) + (cz1*cz2)\n",
        "    scalar_prod = torch.clip(scalar_prod, -1, 1) \n",
        "    distanses = torch.abs(torch.arccos(scalar_prod))   \n",
        "    return torch.mean(distanses), distanses\n",
        "\n",
        "def angle_errors(n1, n2, eps=1e-8):\n",
        "    \"\"\" Calculate angles between two vectors:: n1,n2: (B,3) return: (B,) \"\"\"\n",
        "    n1 = n1 / (torch.linalg.vector_norm(n1, dim=1, keepdims=True) + eps)\n",
        "    n2 = n2 / (torch.linalg.vector_norm(n2, dim=1, keepdims=True) + eps)\n",
        "    \n",
        "    cos = (n1*n2).sum(axis=1)                     # angles between vectors\n",
        "    angle_err = torch.arccos( cos.clip(-1,1) )\n",
        "        \n",
        "    r1   =  n1[:,0]*n1[:,0] + n1[:,1]*n1[:,1]    # angles between vectors in (x,y)    \n",
        "    r2   =  n2[:,0]*n2[:,0] + n2[:,1]*n2[:,1]\n",
        "    cosX = (n1[:,0]*n2[:,0] + n1[:,1]*n2[:,1]) / (torch.sqrt(r1*r2) + eps)    \n",
        "    azimuth_err = torch.arccos( cosX.clip(-1,1) )\n",
        "                                \n",
        "    zerros = r1 < eps                            # azimuth angle not defined\n",
        "\n",
        "    azimuth_err[zerros] = torch.rand((len(n1[zerros]),), dtype=n1.dtype, device=n1.device)*np.pi\n",
        "    \n",
        "    zenith1  = torch.arccos( n1[:,2].clip(-1,1) )\n",
        "    zenith2  = torch.arccos( n2[:,2].clip(-1,1) )\n",
        "    zenith_err = torch.abs(zenith2 - zenith1)\n",
        "        \n",
        "    return angle_err.mean(), azimuth_err.mean(), zenith_err.mean()\n",
        "\n",
        "def angles_to_vectors_2D(angles):\n",
        "    vectors = torch.empty((angles.shape[0], 2), device=angles.device, dtype=angles.dtype)\n",
        "    vectors[:,0] = torch.cos(angles) # x\n",
        "    vectors[:,1] = torch.sin(angles) # y\n",
        "    return vectors\n",
        "\n",
        "def vectors_to_angles_2D(vectors, azimuth=False):\n",
        "    vectors = vectors.clone()\n",
        "    v_squared = vectors.pow(2.0)\n",
        "        \n",
        "    xy_sq = torch.sum(v_squared, axis=1)\n",
        "    xy_d = torch.sqrt(xy_sq)[:, None]\n",
        "        \n",
        "    vectors = torch.where(xy_d == 0, xy_d, vectors/xy_d)\n",
        "\n",
        "    vectors =  torch.clip(vectors, -1, 1)\n",
        "\n",
        "    angles = torch.arccos(vectors[:, 0])\n",
        "    angles = torch.where(torch.isfinite(angles), angles, torch.tensor(0.0, dtype=angles.dtype, device=angles.device))\n",
        "    if azimuth:\n",
        "      angles = torch.where(vectors[:, 1] >= 0, angles, 2*torch.pi - angles) # [0,2pi] range\n",
        "    return angles\n",
        "\n",
        "def angular_dist_score_2D(ang_true, ang_pred):\n",
        "    sa1 = torch.sin(ang_true)\n",
        "    ca1 = torch.cos(ang_true)\n",
        "    sa2 = torch.sin(ang_pred)\n",
        "    ca2 = torch.cos(ang_pred)\n",
        "    scalar_prod = ca1*ca2 + sa1*sa2\n",
        "    scalar_prod = torch.clip(scalar_prod, -1, 1) \n",
        "    distanses = torch.abs(torch.arccos(scalar_prod))   \n",
        "    return torch.mean(distanses), distanses\n",
        "\n",
        "def get_rot_matrix(phi):\n",
        "    s = torch.sin(phi)\n",
        "    c = torch.cos(phi)\n",
        "    rot = torch.stack([torch.stack([c, -s]),\n",
        "                       torch.stack([s, c])])\n",
        "    rot = rot.squeeze(-1)\n",
        "    return rot\n",
        "\n",
        "def build_az_ze_edges(bin_num):\n",
        "    # Create Azimuth Edges\n",
        "    azimuth_edges = torch.tensor(np.linspace(0, 2 * np.pi, bin_num + 1), dtype=torch.float32).to(device)\n",
        "    # Create Zenith Edges\n",
        "    zenith_edges = []\n",
        "    zenith_edges.append(0)\n",
        "    for bin_idx in range(1, bin_num):\n",
        "        zenith_edges.append(np.arccos(np.cos(zenith_edges[-1]) - 2 / (bin_num)))\n",
        "    zenith_edges.append(np.pi)\n",
        "    zenith_edges = torch.tensor(np.array(zenith_edges), dtype=torch.float32).to(device)\n",
        "    return azimuth_edges, zenith_edges\n",
        "\n",
        "def build_angle_bin_vector(azimuth_edges, zenith_edges, bin_num):\n",
        "    angle_bin_zenith0 = np.tile(zenith_edges[:-1], bin_num)\n",
        "    angle_bin_zenith1 = np.tile(zenith_edges[1:], bin_num)\n",
        "    angle_bin_azimuth0 = np.repeat(azimuth_edges[:-1], bin_num)\n",
        "    angle_bin_azimuth1 = np.repeat(azimuth_edges[1:], bin_num)\n",
        "\n",
        "    angle_bin_area = (angle_bin_azimuth1 - angle_bin_azimuth0) * (np.cos(angle_bin_zenith0) - np.cos(angle_bin_zenith1))\n",
        "    angle_bin_vector_sum_x = (np.sin(angle_bin_azimuth1) - np.sin(angle_bin_azimuth0)) * ((angle_bin_zenith1 - angle_bin_zenith0) / 2 - (np.sin(2 * angle_bin_zenith1) - np.sin(2 * angle_bin_zenith0)) / 4)\n",
        "    angle_bin_vector_sum_y = (np.cos(angle_bin_azimuth0) - np.cos(angle_bin_azimuth1)) * ((angle_bin_zenith1 - angle_bin_zenith0) / 2 - (np.sin(2 * angle_bin_zenith1) - np.sin(2 * angle_bin_zenith0)) / 4)\n",
        "    angle_bin_vector_sum_z = (angle_bin_azimuth1 - angle_bin_azimuth0) * ((np.cos(2 * angle_bin_zenith0) - np.cos(2 * angle_bin_zenith1)) / 4)\n",
        "\n",
        "    angle_bin_vector_mean_x = angle_bin_vector_sum_x / angle_bin_area\n",
        "    angle_bin_vector_mean_y = angle_bin_vector_sum_y / angle_bin_area\n",
        "    angle_bin_vector_mean_z = angle_bin_vector_sum_z / angle_bin_area\n",
        "\n",
        "    angle_bin_vector = np.zeros((1, bin_num * bin_num, 3))\n",
        "    angle_bin_vector[:, :, 0] = angle_bin_vector_mean_x\n",
        "    angle_bin_vector[:, :, 1] = angle_bin_vector_mean_y\n",
        "    angle_bin_vector[:, :, 2] = angle_bin_vector_mean_z\n",
        "\n",
        "    angle_bin_vector = torch.tensor(angle_bin_vector, dtype=torch.float32).to(device)\n",
        "    return angle_bin_vector\n",
        "\n",
        "def angles_to_code(angles,bin_num,azimuth_edges,zenith_edges):\n",
        "    azimuth_code = (angles[:, 0] > azimuth_edges[1:].reshape((-1, 1))).sum(axis=0)\n",
        "    zenith_code = (angles[:, 1] > zenith_edges[1:].reshape((-1, 1))).sum(axis=0)\n",
        "    angle_code = bin_num * azimuth_code + zenith_code\n",
        "    return angle_code\n",
        "\n",
        "def code_to_vector(pred, bin_num, angle_bin_vector, max=False, epsilon=1e-8):\n",
        "    # convert prediction to vector\n",
        "    if max:\n",
        "        pred_vector = angle_bin_vector[0,pred.argmax(axis=1)]\n",
        "    else:\n",
        "        pred_vector = (pred.reshape((-1, bin_num * bin_num, 1)) * angle_bin_vector).sum(axis=1)\n",
        "            \n",
        "    # normalize\n",
        "    pred_vector_norm = torch.sqrt((pred_vector**2).sum(axis=1))\n",
        "    mask = pred_vector_norm < epsilon\n",
        "    pred_vector_norm[mask] = 1\n",
        "    \n",
        "    # assign <1, 0, 0> to very small vectors (badly predicted)\n",
        "    pred_vector /= pred_vector_norm.reshape((-1, 1))\n",
        "\n",
        "    pred_vector[mask] = torch.tensor([1., 0., 0.], dtype=pred.dtype, device=pred.device)\n",
        "\n",
        "    return pred_vector\n",
        "\n",
        "def code_to_angle(pred, bin_num, angle_bin_vector, max=False, epsilon=1e-8):\n",
        "    # convert prediction to vector\n",
        "    pred_vector = code_to_vector(pred, bin_num, angle_bin_vector, max, epsilon)\n",
        "\n",
        "    # convert to angle\n",
        "    azimuth = torch.arctan2(pred_vector[:, 1], pred_vector[:, 0])\n",
        "    azimuth[azimuth < 0] += 2 * torch.pi\n",
        "    zenith = torch.arccos(pred_vector[:, 2])\n",
        "\n",
        "    angles = torch.cat([azimuth.view(-1,1), zenith.view(-1,1)], axis=1)\n",
        "    return angles\n",
        "\n",
        "class Lion(Optimizer):\n",
        "  r\"\"\"Implements Lion algorithm.\"\"\"\n",
        "\n",
        "  def __init__(self, params, lr=1e-4, betas=(0.9, 0.99), weight_decay=0.0):\n",
        "    \"\"\"Initialize the hyperparameters.\n",
        "    Args:\n",
        "      params (iterable): iterable of parameters to optimize or dicts defining\n",
        "        parameter groups\n",
        "      lr (float, optional): learning rate (default: 1e-4)\n",
        "      betas (Tuple[float, float], optional): coefficients used for computing\n",
        "        running averages of gradient and its square (default: (0.9, 0.99))\n",
        "      weight_decay (float, optional): weight decay coefficient (default: 0)\n",
        "    \"\"\"\n",
        "\n",
        "    if not 0.0 <= lr:\n",
        "      raise ValueError('Invalid learning rate: {}'.format(lr))\n",
        "    if not 0.0 <= betas[0] < 1.0:\n",
        "      raise ValueError('Invalid beta parameter at index 0: {}'.format(betas[0]))\n",
        "    if not 0.0 <= betas[1] < 1.0:\n",
        "      raise ValueError('Invalid beta parameter at index 1: {}'.format(betas[1]))\n",
        "    defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n",
        "    super().__init__(params, defaults)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def step(self, closure=None):\n",
        "    \"\"\"Performs a single optimization step.\n",
        "    Args:\n",
        "      closure (callable, optional): A closure that reevaluates the model\n",
        "        and returns the loss.\n",
        "    Returns:\n",
        "      the loss.\n",
        "    \"\"\"\n",
        "    loss = None\n",
        "    if closure is not None:\n",
        "      with torch.enable_grad():\n",
        "        loss = closure()\n",
        "\n",
        "    for group in self.param_groups:\n",
        "      for p in group['params']:\n",
        "        if p.grad is None:\n",
        "          continue\n",
        "\n",
        "        # Perform stepweight decay\n",
        "        p.data.mul_(1 - group['lr'] * group['weight_decay'])\n",
        "\n",
        "        grad = p.grad\n",
        "        state = self.state[p]\n",
        "        # State initialization\n",
        "        if len(state) == 0:\n",
        "          # Exponential moving average of gradient values\n",
        "          state['exp_avg'] = torch.zeros_like(p)\n",
        "\n",
        "        exp_avg = state['exp_avg']\n",
        "        beta1, beta2 = group['betas']\n",
        "\n",
        "        # Weight update\n",
        "        update = exp_avg * beta1 + grad * (1 - beta1)\n",
        "        p.add_(torch.sign(update), alpha=-group['lr'])\n",
        "        # Decay the momentum running average coefficient\n",
        "        exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)\n",
        "\n",
        "    return loss\n",
        "\n",
        "class PiecewiseLinearLR(_LRScheduler):\n",
        "    \"\"\"Interpolate learning rate linearly between milestones.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        optimizer: Optimizer,\n",
        "        milestones: List[int],\n",
        "        factors: List[float],\n",
        "        last_epoch: int = -1,\n",
        "        verbose: bool = False,\n",
        "    ):\n",
        "        \"\"\"Construct `PiecewiseLinearLR`.\n",
        "\n",
        "        For each milestone, denoting a specified number of steps, a factor\n",
        "        multiplying the base learning rate is specified. For steps between two\n",
        "        milestones, the learning rate is interpolated linearly between the two\n",
        "        closest milestones. For steps before the first milestone, the factor\n",
        "        for the first milestone is used; vice versa for steps after the last\n",
        "        milestone.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Wrapped optimizer.\n",
        "            milestones: List of step indices. Must be increasing.\n",
        "            factors: List of multiplicative factors. Must be same length as\n",
        "                `milestones`.\n",
        "            last_epoch: The index of the last epoch.\n",
        "            verbose: If ``True``, prints a message to stdout for each update.\n",
        "        \"\"\"\n",
        "        # Check(s)\n",
        "        if milestones != sorted(milestones):\n",
        "            raise ValueError(\"Milestones must be increasing\")\n",
        "        if len(milestones) != len(factors):\n",
        "            raise ValueError(\n",
        "                \"Only multiplicative factor must be specified for each milestone.\"\n",
        "            )\n",
        "\n",
        "        self.milestones = milestones\n",
        "        self.factors = factors\n",
        "        super().__init__(optimizer, last_epoch, verbose)\n",
        "\n",
        "    def _get_factor(self) -> np.ndarray:\n",
        "        # Linearly interpolate multiplicative factor between milestones.\n",
        "        return np.interp(self.last_epoch, self.milestones, self.factors)\n",
        "\n",
        "    def get_lr(self) -> List[float]:\n",
        "        \"\"\"Get effective learning rate(s) for each optimizer.\"\"\"\n",
        "        if not self._get_lr_called_within_step:\n",
        "            warnings.warn(\n",
        "                \"To get the last learning rate computed by the scheduler, \"\n",
        "                \"please use `get_last_lr()`.\",\n",
        "                UserWarning,\n",
        "            )\n",
        "        return [base_lr * self._get_factor() for base_lr in self.base_lrs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXX9mHPitdm9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Conv\n",
        "\n",
        "\"\"\"Class(es) implementing layers to be used in `graphnet` models.\"\"\"\n",
        "\n",
        "from typing import Any, Callable, Optional, Sequence, Union\n",
        "\n",
        "from torch.functional import Tensor\n",
        "from torch_geometric.nn import EdgeConv, TransformerConv\n",
        "from torch_geometric.nn.pool import knn_graph\n",
        "from torch_geometric.typing import Adj\n",
        "from pytorch_lightning import LightningModule\n",
        "\n",
        "class DynEdgeConv(EdgeConv, LightningModule):\n",
        "    \"\"\"Dynamical edge convolution layer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,\n",
        "        aggr: str = \"max\",\n",
        "        nb_neighbors: int = 8,\n",
        "        features_subset: Optional[Union[Sequence[int], slice]] = None,\n",
        "        last_layer = False,\n",
        "        **kwargs: Any,\n",
        "    ):\n",
        "        \"\"\"Construct `DynEdgeConv`.\n",
        "\n",
        "        Args:\n",
        "            nn: The MLP/torch.Module to be used within the `EdgeConv`.\n",
        "            aggr: Aggregation method to be used with `EdgeConv`.\n",
        "            nb_neighbors: Number of neighbours to be clustered after the\n",
        "                `EdgeConv` operation.\n",
        "            features_subset: Subset of features in `Data.x` that should be used\n",
        "                when dynamically performing the new graph clustering after the\n",
        "                `EdgeConv` operation. Defaults to all features.\n",
        "            **kwargs: Additional features to be passed to `EdgeConv`.\n",
        "        \"\"\"\n",
        "        # Check(s)\n",
        "        if features_subset is None:\n",
        "            features_subset = slice(None)  # Use all features\n",
        "        assert isinstance(features_subset, (list, slice))\n",
        "\n",
        "        # Base class constructor\n",
        "        super().__init__(nn=nn, aggr=aggr, **kwargs)\n",
        "\n",
        "        # Additional member variables\n",
        "        self.nb_neighbors = nb_neighbors\n",
        "        self.features_subset = features_subset\n",
        "        self.last_layer = last_layer\n",
        "\n",
        "    def forward(\n",
        "        self, x: Tensor, edge_index: Adj, batch: Optional[Tensor] = None\n",
        "    ) -> Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        # Standard EdgeConv forward pass\n",
        "        x = super().forward(x, edge_index)\n",
        "\n",
        "        if not self.last_layer:   # unnesessary last layer\n",
        "            # Recompute adjacency\n",
        "            edge_index = knn_graph(\n",
        "                x=x[:,self.features_subset],\n",
        "                k=self.nb_neighbors,\n",
        "                batch=batch,\n",
        "            ).to(self.device)\n",
        "\n",
        "        return x, edge_index\n",
        "\n",
        "\n",
        "class DynTransformerConv(TransformerConv, LightningModule):\n",
        "    \"\"\"Dynamical edge convolution layer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_channels, \n",
        "        out_channels: int, \n",
        "        nb_neighbors: int = 8,\n",
        "        features_subset: Optional[Union[Sequence[int], slice]] = None,\n",
        "        last_layer = False,\n",
        "        heads: int = 1, \n",
        "        concat: bool = True, \n",
        "        beta: bool = False, \n",
        "        dropout: float = 0.0, \n",
        "        edge_dim: Optional[int] = None, \n",
        "        bias: bool = True, \n",
        "        root_weight: bool = True, **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Check(s)\n",
        "        if features_subset is None:\n",
        "            features_subset = slice(None)  # Use all features\n",
        "        assert isinstance(features_subset, (list, slice))\n",
        "\n",
        "        # Base class constructor\n",
        "        super().__init__(in_channels=in_channels, out_channels=out_channels, \n",
        "                         heads=heads, concat=concat, beta=beta, dropout=dropout, edge_dim=edge_dim, bias=bias, \n",
        "                         root_weight=root_weight, **kwargs)\n",
        "\n",
        "        # Additional member variables\n",
        "        self.nb_neighbors = nb_neighbors\n",
        "        self.features_subset = features_subset\n",
        "        self.last_layer = last_layer\n",
        "\n",
        "    def forward(\n",
        "        self, x: Tensor, edge_index: Adj, batch: Optional[Tensor] = None\n",
        "    ) -> Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        # Standard EdgeConv forward pass\n",
        "        x = super().forward(x, edge_index)\n",
        "\n",
        "        if not self.last_layer:   # unnesessary last layer\n",
        "            # Recompute adjacency\n",
        "            edge_index = knn_graph(\n",
        "                x=x[:,self.features_subset],\n",
        "                k=self.nb_neighbors,\n",
        "                batch=batch,\n",
        "            ).to(self.device)\n",
        "\n",
        "        return x, edge_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwwSiwSarNiB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title DynEdge\n",
        "\n",
        "\"\"\"Implementation of the DynEdge GNN model architecture.\"\"\"\n",
        "from typing import List, Optional, Sequence, Tuple, Union\n",
        "\n",
        "import torch\n",
        "from torch import Tensor, LongTensor\n",
        "from torch_geometric.data import Data\n",
        "from torch_scatter import scatter_max, scatter_mean, scatter_min, scatter_sum\n",
        "\n",
        "# from graphnet.models.components.layers import DynEdgeConv  # QuData: owerwrite\n",
        "from graphnet.utilities.config import save_model_config\n",
        "from graphnet.models.gnn.gnn import GNN\n",
        "from torch_geometric.utils.homophily import homophily\n",
        "from torch_geometric.nn.pool import TopKPooling\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "\n",
        "GLOBAL_POOLINGS = {\n",
        "    \"min\": scatter_min,\n",
        "    \"max\": scatter_max,\n",
        "    \"sum\": scatter_sum,\n",
        "    \"mean\": scatter_mean,\n",
        "}\n",
        "\n",
        "def calculate_xyzt_homophily(\n",
        "    x: Tensor, edge_index: LongTensor, batch: Batch\n",
        ") -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
        "    \"\"\"Calculate xyzt-homophily from a batch of graphs.\n",
        "\n",
        "    Homophily is a graph scalar quantity that measures the likeness of\n",
        "    variables in nodes. Notice that this calculator assumes a special order of\n",
        "    input features in x.\n",
        "\n",
        "    Returns:\n",
        "        Tuple, each element with shape [batch_size,1].\n",
        "    \"\"\"\n",
        "    hx = homophily(edge_index, x[:, 0], batch).reshape(-1, 1)\n",
        "    hy = homophily(edge_index, x[:, 1], batch).reshape(-1, 1)\n",
        "    hz = homophily(edge_index, x[:, 2], batch).reshape(-1, 1)\n",
        "    ht = homophily(edge_index, x[:, -3], batch).reshape(-1, 1) # for dynamic reshape\n",
        "    return hx, hy, hz, ht\n",
        "\n",
        "\n",
        "class DynEdge(GNN):\n",
        "    \"\"\"DynEdge (dynamical edge convolutional) model.\"\"\"\n",
        "\n",
        "    @save_model_config\n",
        "    def __init__(\n",
        "        self,\n",
        "        nb_inputs: int,\n",
        "        *,\n",
        "        nb_neighbours: int = 8,\n",
        "        features_subset: Optional[Union[List[int], slice]] = None,\n",
        "        dynedge_layers = None,\n",
        "        post_processing_layer_sizes: Optional[List[int]] = None,\n",
        "        post_processing_transformer: Optional[Dict] = None,\n",
        "        readout_layer_sizes: Optional[List[int]] = None,\n",
        "        global_pooling: Optional[Dict] = None,\n",
        "        add_global_variables_after_pooling: bool = False,\n",
        "        sensor_embedding = False,\n",
        "        local_pooling = None \n",
        "    ):\n",
        "        \"\"\"Construct `DynEdge`.\n",
        "\n",
        "        Args:\n",
        "            nb_inputs: Number of input features on each node.\n",
        "            nb_neighbours: Number of neighbours to used in the k-nearest\n",
        "                neighbour clustering which is performed after each (dynamical)\n",
        "                edge convolution.\n",
        "            features_subset: The subset of latent features on each node that\n",
        "                are used as metric dimensions when performing the k-nearest\n",
        "                neighbours clustering. Defaults to [0,1,2].\n",
        "            dynedge_layer_sizes: The layer sizes, or latent feature dimenions,\n",
        "                used in the `DynEdgeConv` layer. Each entry in\n",
        "                `dynedge_layer_sizes` corresponds to a single `DynEdgeConv`\n",
        "                layer; the integers in the corresponding tuple corresponds to\n",
        "                the layer sizes in the multi-layer perceptron (MLP) that is\n",
        "                applied within each `DynEdgeConv` layer. That is, a list of\n",
        "                size-two tuples means that all `DynEdgeConv` layers contain a\n",
        "                two-layer MLP.\n",
        "                Defaults to [(128, 256), (336, 256), (336, 256), (336, 256)].\n",
        "            post_processing_layer_sizes: Hidden layer sizes in the MLP\n",
        "                following the skip-concatenation of the outputs of each\n",
        "                `DynEdgeConv` layer. Defaults to [336, 256].\n",
        "            readout_layer_sizes: Hidden layer sizes in the MLP following the\n",
        "                post-processing _and_ optional global pooling. As this is the\n",
        "                last layer(s) in the model, the last layer in the read-out\n",
        "                yields the output of the `DynEdge` model. Defaults to [128,].\n",
        "            global_pooling_schemes: The list global pooling schemes to use.\n",
        "                Options are: \"min\", \"max\", \"mean\", and \"sum\".\n",
        "            add_global_variables_after_pooling: Whether to add global variables\n",
        "                after global pooling. The alternative is to  added (distribute)\n",
        "                them to the individual nodes before any convolutional\n",
        "                operations.\n",
        "        \"\"\"\n",
        "        # Latent feature subset for computing nearest neighbours in DynEdge.\n",
        "        if features_subset is None:\n",
        "            features_subset = slice(0, 3)\n",
        "\n",
        "\n",
        "        self._dynedge_layers = dynedge_layers\n",
        "        self._post_processing_layer_sizes = post_processing_layer_sizes\n",
        "        self._post_processing_transformer = post_processing_transformer\n",
        "        self._local_pooling_conf = local_pooling\n",
        "\n",
        "        # Read-out layer sizes\n",
        "        if readout_layer_sizes is None:\n",
        "            readout_layer_sizes = [\n",
        "                128,\n",
        "            ]\n",
        "\n",
        "        assert isinstance(readout_layer_sizes, list)\n",
        "        assert len(readout_layer_sizes)\n",
        "        assert all(size > 0 for size in readout_layer_sizes)\n",
        "\n",
        "        self._readout_layer_sizes = readout_layer_sizes\n",
        "\n",
        "        # Global pooling scheme(s)\n",
        "        if global_pooling is None:\n",
        "            global_pooling = {\"type\": \"simple\", \"schemes\": [\"min\",\"max\",\"mean\"], \"nb_out\": 768}\n",
        "\n",
        "        self._global_pooling_conf = global_pooling\n",
        "        self._global_pooling_model = None\n",
        "\n",
        "        self._add_global_variables_after_pooling = (\n",
        "            add_global_variables_after_pooling\n",
        "        )\n",
        "\n",
        "        # Base class constructor\n",
        "        super().__init__(nb_inputs, self._readout_layer_sizes[-1])\n",
        "\n",
        "        # Remaining member variables()\n",
        "        self._activation = torch.nn.LeakyReLU()\n",
        "        self._nb_inputs = nb_inputs\n",
        "        self._nb_global_variables = 5 + nb_inputs\n",
        "        self._nb_neighbours = nb_neighbours\n",
        "        self._features_subset = features_subset\n",
        "\n",
        "        self._sensor_embed = None\n",
        "        if sensor_embedding:            \n",
        "            sensor_embed_init_weights = torch.zeros((5160, 8), dtype=torch.float32, device=device)\n",
        "            sensor_embed_init_weights[:,:4] = 1.0\n",
        "            self._sensor_embed = torch.nn.Embedding(5160, 8, _weight=sensor_embed_init_weights)\n",
        "\n",
        "        self._construct_layers()\n",
        "        \n",
        "        self._local_pooling = None        \n",
        "        if self._local_pooling_conf:\n",
        "            if self._local_pooling_conf[\"type\"] == \"TopKPooling\":\n",
        "                self._local_pooling = TopKPooling(self._post_processing_layer_sizes[-1],self._local_pooling_conf[\"k\"])\n",
        "\n",
        "        if self._global_pooling_conf[\"type\"] == \"GRU\":\n",
        "            self._global_pooling_model = torch.nn.GRU(input_size=self._global_pooling_conf[\"nb_in\"],\n",
        "                                                      hidden_size=int(self._global_pooling_conf[\"nb_out\"]/2),\n",
        "                                                      batch_first=True,\n",
        "                                                      bidirectional=self._global_pooling_conf[\"bidirectional\"])\n",
        "\n",
        "    def build_dyn_edge_conv_layer(self, conf, nb_latent_features, last_layer):\n",
        "        sizes = conf['sizes']\n",
        "        layers = []\n",
        "        layer_sizes = [nb_latent_features] + list(sizes)\n",
        "        for ix, (nb_in, nb_out) in enumerate(\n",
        "            zip(layer_sizes[:-1], layer_sizes[1:])\n",
        "        ):\n",
        "            if ix == 0:\n",
        "                nb_in *= 2\n",
        "            layers.append(torch.nn.Linear(nb_in, nb_out))\n",
        "            layers.append(self._activation)\n",
        "        \n",
        "        conv_layer = DynEdgeConv(\n",
        "                torch.nn.Sequential(*layers),\n",
        "                aggr=\"add\",\n",
        "                nb_neighbors=self._nb_neighbours,\n",
        "                features_subset=self._features_subset,\n",
        "                last_layer=last_layer\n",
        "            )\n",
        "        return conv_layer, nb_out\n",
        "\n",
        "    def build_transformer_conv_layer(self, conf, nb_latent_features, last_layer):\n",
        "        conv_layer = DynTransformerConv(\n",
        "                in_channels=nb_latent_features,\n",
        "                out_channels=conf['nb_out'],\n",
        "                heads=conf['heads'],\n",
        "                nb_neighbors=self._nb_neighbours,\n",
        "                features_subset=self._features_subset,\n",
        "                last_layer=last_layer\n",
        "            )\n",
        "        return conv_layer, conf['nb_out']\n",
        "\n",
        "    def build_layer(self, layer_conf, nb_latent_features, last_layer):\n",
        "        if layer_conf['type'] == 'DynEdgeConv':\n",
        "            return self.build_dyn_edge_conv_layer(layer_conf, nb_latent_features, last_layer)\n",
        "        if layer_conf['type'] == 'TransformerConv':\n",
        "            return self.build_transformer_conv_layer(layer_conf, nb_latent_features, last_layer)\n",
        "\n",
        "    def _construct_layers(self) -> None:\n",
        "        \"\"\"Construct layers (torch.nn.Modules).\"\"\"\n",
        "        # Convolutional operations\n",
        "        nb_input_features = self._nb_inputs\n",
        "        if not self._add_global_variables_after_pooling:\n",
        "            nb_input_features += self._nb_global_variables\n",
        "\n",
        "        self._conv_layers = torch.nn.ModuleList()\n",
        "        nb_latent_features = nb_input_features\n",
        "        for layer_conf in self._dynedge_layers:\n",
        "            last_layer = len(self._conv_layers) == (len(self._dynedge_layers) - 1) # qudata: unnessesary last layer\n",
        "            conv_layer, nb_out = self.build_layer(layer_conf, nb_latent_features, last_layer)\n",
        "            self._conv_layers.append(conv_layer)\n",
        "            nb_latent_features = nb_out\n",
        "\n",
        "        # Post-processing operations\n",
        "        nb_latent_features = (\n",
        "            sum(layer_conf['nb_out'] for layer_conf in self._dynedge_layers)\n",
        "            + nb_input_features\n",
        "        )\n",
        "\n",
        "        post_processing_layers = []\n",
        "        if self._post_processing_layer_sizes:\n",
        "            \n",
        "            layer_sizes = [nb_latent_features] + list(\n",
        "                self._post_processing_layer_sizes\n",
        "            )\n",
        "            for nb_in, nb_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
        "                post_processing_layers.append(torch.nn.Linear(nb_in, nb_out))\n",
        "                post_processing_layers.append(self._activation)            \n",
        "\n",
        "        if self._post_processing_transformer:\n",
        "            encoder_layer = torch.nn.TransformerEncoderLayer(\n",
        "                                                             d_model=self._post_processing_transformer[\"d_model\"], \n",
        "                                                             nhead=self._post_processing_transformer[\"nhead\"],\n",
        "                                                             dim_feedforward=self._post_processing_transformer[\"dim_feedforward\"]\n",
        "                                                            )\n",
        "            post_processing_layers.append(torch.nn.TransformerEncoder(encoder_layer, self._post_processing_transformer[\"num_layers\"]))\n",
        "\n",
        "        self._post_processing = torch.nn.Sequential(*post_processing_layers)\n",
        "\n",
        "        # Read-out operations\n",
        "        nb_latent_features = self._global_pooling_conf[\"nb_out\"]\n",
        "\n",
        "        if self._add_global_variables_after_pooling:\n",
        "            nb_latent_features += self._nb_global_variables\n",
        "\n",
        "        readout_layers = []\n",
        "        layer_sizes = [nb_latent_features] + list(self._readout_layer_sizes)\n",
        "        for nb_in, nb_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
        "            readout_layers.append(torch.nn.Linear(nb_in, nb_out))\n",
        "            readout_layers.append(self._activation)\n",
        "\n",
        "        self._readout = torch.nn.Sequential(*readout_layers)\n",
        "\n",
        "    def _global_pooling_simple(self, x: Tensor, batch: LongTensor) -> Tensor:\n",
        "        \"\"\"Perform global pooling.\"\"\"\n",
        "        pooled = []\n",
        "        for pooling_scheme in self._global_pooling_conf[\"schemes\"]:\n",
        "            pooling_fn = GLOBAL_POOLINGS[pooling_scheme]\n",
        "            pooled_x = pooling_fn(x, index=batch, dim=0)\n",
        "            if isinstance(pooled_x, tuple) and len(pooled_x) == 2:\n",
        "                # `scatter_{min,max}`, which return also an argument, vs.\n",
        "                # `scatter_{mean,sum}`\n",
        "                pooled_x, _ = pooled_x\n",
        "            pooled.append(pooled_x)\n",
        "        pooled = torch.cat(pooled, dim=1)\n",
        "        return pooled\n",
        "\n",
        "    def _global_pooling_gru(self, x: Tensor, batch: LongTensor) -> Tensor:\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        pooled = self._global_pooling_model(x)[0][:, -1]\n",
        "        return pooled\n",
        "\n",
        "    def _global_pooling(self, x: Tensor, batch: LongTensor) -> Tensor:\n",
        "        if self._global_pooling_conf[\"type\"] == \"simple\":\n",
        "            return self._global_pooling_simple(x, batch)\n",
        "        if self._global_pooling_conf[\"type\"] == \"GRU\":\n",
        "            return self._global_pooling_gru(x, batch)\n",
        "\n",
        "    def _calculate_global_variables(\n",
        "        self,\n",
        "        x: Tensor,\n",
        "        edge_index: LongTensor,\n",
        "        batch: LongTensor,\n",
        "        *additional_attributes: Tensor,\n",
        "    ) -> Tensor:\n",
        "        \"\"\"Calculate global variables.\"\"\"\n",
        "        # Calculate homophily (scalar variables)\n",
        "        h_x, h_y, h_z, h_t = calculate_xyzt_homophily(x, edge_index, batch)\n",
        "\n",
        "        # Calculate mean features\n",
        "        global_means = scatter_mean(x, batch, dim=0)\n",
        "\n",
        "        # Add global variables\n",
        "        global_variables = torch.cat(\n",
        "            [\n",
        "                global_means,\n",
        "                h_x,\n",
        "                h_y,\n",
        "                h_z,\n",
        "                h_t,\n",
        "            ]\n",
        "            + [attr.unsqueeze(dim=1) for attr in additional_attributes],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        return global_variables\n",
        "\n",
        "    def forward(self, data: Data) -> Tensor:\n",
        "        \"\"\"Apply learnable forward pass.\"\"\"\n",
        "        if CFG.FROZEN: torch.set_grad_enabled(False) \n",
        "\n",
        "        # Convenience variables\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # Sensor embeddings\n",
        "        if self._sensor_embed:    \n",
        "            #with torch.no_grad():         \n",
        "            s_emb = self._sensor_embed(data.sensor_id)\n",
        "            x[:,:4] = x[:,:4] * s_emb[:,:4] + s_emb[:,4:] # x,y,z,t * wx,wy,wz,wt + ax,ay,az,at\n",
        "\n",
        "        global_variables = self._calculate_global_variables(\n",
        "            x,\n",
        "            edge_index,\n",
        "            batch,\n",
        "            torch.log10(data.n_pulses),\n",
        "        )\n",
        "\n",
        "        # Distribute global variables out to each node\n",
        "        if not self._add_global_variables_after_pooling:\n",
        "            distribute = (\n",
        "                batch.unsqueeze(dim=1) == torch.unique(batch).unsqueeze(dim=0)\n",
        "            ).type(torch.float)\n",
        "\n",
        "            global_variables_distributed = torch.sum(\n",
        "                distribute.unsqueeze(dim=2)\n",
        "                * global_variables.unsqueeze(dim=0),\n",
        "                dim=1,\n",
        "            )\n",
        "\n",
        "            x = torch.cat((x, global_variables_distributed), dim=1)\n",
        "\n",
        "        # DynEdge-convolutions\n",
        "        skip_connections = [x]\n",
        "        for conv_layer_idx, conv_layer in enumerate(self._conv_layers): \n",
        "            if CFG.FROZEN and self.training and conv_layer_idx in CFG.UNFOROZEN_LAYERS: torch.set_grad_enabled(True)\n",
        "            x, edge_index = conv_layer(x, edge_index, batch)\n",
        "            skip_connections.append(x)\n",
        "\n",
        "        # Skip-cat\n",
        "        x = torch.cat(skip_connections, dim=1)\n",
        "\n",
        "        # Post-processing        \n",
        "        x = self._post_processing(x)\n",
        "\n",
        "        if self._local_pooling:\n",
        "            x, edge_index, _, batch, _, _ = self._local_pooling(x, edge_index, None, batch)\n",
        "\n",
        "        # (Optional) Global pooling\n",
        "        if self._global_pooling_conf:\n",
        "            x = self._global_pooling(x, batch=batch)\n",
        "            if self._add_global_variables_after_pooling:\n",
        "                x = torch.cat(\n",
        "                    [\n",
        "                        x,\n",
        "                        global_variables,\n",
        "                    ],\n",
        "                    dim=1,\n",
        "                )\n",
        "\n",
        "        if CFG.FROZEN and self.training: torch.set_grad_enabled(True) \n",
        "\n",
        "        # Read-out\n",
        "        x = self._readout(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ1buDDfmwF5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title GraphNet\n",
        "\n",
        "from graphnet.data.constants import FEATURES, TRUTH\n",
        "from graphnet.models import StandardModel\n",
        "from graphnet.models.detector.icecube import IceCubeKaggle\n",
        "#from graphnet.models.gnn import DynEdge # QuData: owerwrite\n",
        "from graphnet.models.graph_builders import KNNGraphBuilder\n",
        "from graphnet.models.task.reconstruction import DirectionReconstructionWithKappa, ZenithReconstructionWithKappa, AzimuthReconstructionWithKappa\n",
        "from graphnet.training.callbacks import ProgressBar\n",
        "from graphnet.training.loss_functions import VonMisesFisher3DLoss, VonMisesFisher2DLoss\n",
        "from graphnet.training.labels import Direction\n",
        "from graphnet.utilities.logging import get_logger\n",
        "from graphnet.models.graph_builders import GraphBuilder\n",
        "from graphnet.models.detector.detector import Detector\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import ModuleList\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "from graphnet.models.coarsening import Coarsening\n",
        "from graphnet.utilities.config import save_model_config\n",
        "from graphnet.models.detector.detector import Detector\n",
        "from graphnet.models.gnn.gnn import GNN\n",
        "from graphnet.models.model import Model\n",
        "from graphnet.models.task import Task\n",
        "from torch.nn.functional import cosine_similarity, normalize\n",
        "from graphnet.training.loss_functions import LossFunction\n",
        "from graphnet.utilities.maths import eps_like\n",
        "\n",
        "\n",
        "class CosineLoss(LossFunction):\n",
        "    def _forward(self, preds, target):\n",
        "        target = target.reshape(-1, 3)\n",
        "        return 1 - cosine_similarity(preds[:,:3], target, dim=1, eps=1e-8)\n",
        "\n",
        "class CosineLoss2D(LossFunction):\n",
        "    def _forward(self, preds, target):\n",
        "        target = target.reshape(-1, 2)\n",
        "        return 1 - cosine_similarity(preds[:,:2], target, dim=1, eps=1e-8)\n",
        "\n",
        "class VMFCustomLoss(LossFunction):\n",
        "    def _forward(self, preds, target, eps = 1e-8, kappa0=10):\n",
        "        target = target.reshape(-1, 3)          \n",
        "        kappa = preds[:,3] \n",
        "        preds = preds[:,:3]*kappa.unsqueeze(1)\n",
        "        logC  = -kappa + torch.log(kappa+eps) \n",
        "        mask  = kappa < kappa0\n",
        "        ka    = kappa[mask]\n",
        "        logC[mask] = torch.log( ka / ( torch.exp(ka) - torch.exp(-ka) + eps) )        \n",
        "        return -(preds* target).sum(axis=1) - logC\n",
        "\n",
        "class VMFCustomLoss2(LossFunction):\n",
        "    def _forward(self, preds, target, eps = 1e-8, kappa0=10):    \n",
        "        target = target.reshape(-1, 3)      \n",
        "        kappa = preds[:,3] \n",
        "        preds = preds[:,:3]*kappa.unsqueeze(1)\n",
        "        logC  = torch.log(kappa/(1-torch.exp(-2*kappa))+eps) - kappa\n",
        "        return -( (n_true*n_pred).sum(axis=1) + logC)\n",
        "\n",
        "class IceCubeCustom(Detector):\n",
        "    \"\"\"`Detector` class for Kaggle Competition.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, graph_builder: GraphBuilder, scalers: List[dict] = None, features = None\n",
        "    ):\n",
        "        self._features = features\n",
        "\n",
        "        super().__init__(graph_builder, scalers)\n",
        "\n",
        "    @property\n",
        "    def features(self) -> List[str]:\n",
        "        return self._features\n",
        "\n",
        "    def _forward(self, data: Data) -> Data:\n",
        "        \"\"\"Ingest data, build graph, and preprocess features.\n",
        "\n",
        "        Args:\n",
        "            data: Input graph data.\n",
        "\n",
        "        Returns:\n",
        "            Connected and preprocessed graph data.\n",
        "        \"\"\"\n",
        "        # Check(s)\n",
        "        #self._validate_features(data)\n",
        "\n",
        "        # Preprocessing\n",
        "        data.x[:, 0] /= 500.0  # x\n",
        "        data.x[:, 1] /= 500.0  # y\n",
        "        data.x[:, 2] /= 500.0  # z\n",
        "        data.x[:, -3] = (data.x[:, -3] - 1.0e04) / 3.0e4  # time\n",
        "        data.x[:, -2] = torch.log10(data.x[:, -2]) / 3.0  # charge\n",
        "\n",
        "        return data\n",
        "\n",
        "class DirectionReconstructionWithKappa2D(Task):\n",
        "    \"\"\"Reconstructs direction with kappa from the 3D-vMF distribution.\"\"\"\n",
        "\n",
        "    # Requires three features: untransformed points in (x,y,z)-space.\n",
        "    nb_inputs = 2\n",
        "\n",
        "    def _forward(self, x: Tensor) -> Tensor:\n",
        "        # Transform outputs to angle and prepare prediction\n",
        "        kappa = torch.linalg.vector_norm(x, dim=1) + eps_like(x)\n",
        "        vec_x = x[:, 0] / kappa\n",
        "        vec_y = x[:, 1] / kappa\n",
        "        return torch.stack((vec_x, vec_y, kappa), dim=1)\n",
        "\n",
        "class DirectionReconstructionWithBins(Task):\n",
        "    \"\"\"Reconstructs direction with kappa from the 3D-vMF distribution.\"\"\"\n",
        "\n",
        "    # Requires three features: untransformed points in (x,y,z)-space.\n",
        "    nb_inputs = 576\n",
        "\n",
        "    def _forward(self, x: Tensor) -> Tensor:\n",
        "        return x\n",
        "\n",
        "\"\"\"Standard model class(es).\"\"\"\n",
        "class StandardCustomModel(Model):\n",
        "    \"\"\"Main class for standard models in graphnet.\n",
        "\n",
        "    This class chains together the different elements of a complete GNN-based\n",
        "    model (detector read-in, GNN architecture, and task-specific read-outs).\n",
        "    \"\"\"\n",
        "\n",
        "    @save_model_config\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        detector: Detector,\n",
        "        gnn: GNN,\n",
        "        tasks: Union[Task, List[Task]],\n",
        "        coarsening: Optional[Coarsening] = None,\n",
        "        optimizer_class: type = Adam,\n",
        "        optimizer_kwargs: Optional[Dict] = None,\n",
        "        scheduler_class: Optional[type] = None,\n",
        "        scheduler_kwargs: Optional[Dict] = None,\n",
        "        scheduler_config: Optional[Dict] = None     \n",
        "    ) -> None:\n",
        "        \"\"\"Construct `StandardModel`.\"\"\"\n",
        "        # Base class constructor\n",
        "        super().__init__()\n",
        "\n",
        "        # Check(s)\n",
        "        if isinstance(tasks, Task):\n",
        "            tasks = [tasks]\n",
        "        assert isinstance(tasks, (list, tuple))\n",
        "        assert all(isinstance(task, Task) for task in tasks)\n",
        "        assert isinstance(detector, Detector)\n",
        "        assert isinstance(gnn, GNN)\n",
        "        assert coarsening is None or isinstance(coarsening, Coarsening)\n",
        "\n",
        "        # Member variable(s)\n",
        "        self._detector = detector\n",
        "        self._gnn = gnn\n",
        "        self._tasks = ModuleList(tasks)\n",
        "        self._coarsening = coarsening\n",
        "\n",
        "    def forward(self, data: Data) -> List[Union[Tensor, Data]]:\n",
        "        \"\"\"Forward pass, chaining model components.\"\"\"\n",
        "        if CFG.FROZEN: torch.set_grad_enabled(False) \n",
        "        if self._coarsening:\n",
        "            data = self._coarsening(data)\n",
        "        data = self._detector(data)\n",
        "        x = self._gnn(data)\n",
        "        preds = [task(x) for task in self._tasks]\n",
        "        return preds\n",
        "\n",
        "    def compute_loss(\n",
        "        self, preds: Tensor, data: Data, verbose: bool = False\n",
        "    ) -> Tensor:\n",
        "        \"\"\"Compute and sum losses across tasks.\"\"\"\n",
        "        losses = [\n",
        "            task.compute_loss(pred, data)\n",
        "            for task, pred in zip(self._tasks, preds)\n",
        "        ]\n",
        "        if verbose:\n",
        "            self.info(f\"{losses}\")\n",
        "        assert all(\n",
        "            loss.dim() == 0 for loss in losses\n",
        "        ), \"Please reduce loss for each task separately\"\n",
        "        return torch.sum(torch.stack(losses))\n",
        "\n",
        "    def _get_batch_size(self, data: Data) -> int:\n",
        "        return torch.numel(torch.unique(data.batch))\n",
        "\n",
        "def build_model(config: Dict[str,Any]) -> StandardModel:\n",
        "    \"\"\"Builds GNN from config\"\"\"\n",
        "    # Building model\n",
        "\n",
        "    if not \"mode\" in config:\n",
        "        config[\"mode\"] = \"regression\"\n",
        "\n",
        "    len_train_dataloader = 1000 # len(train_dataloader)\n",
        "\n",
        "    detector = IceCubeCustom(\n",
        "        graph_builder=KNNGraphBuilder(\n",
        "              nb_nearest_neighbours=config[\"neighbours\"][0],\n",
        "              columns=config[\"features_subset\"]\n",
        "            ),\n",
        "        features=config[\"features\"]\n",
        "    )    \n",
        "    gnn = DynEdge(\n",
        "        #nb_inputs=detector.nb_outputs,\n",
        "        nb_inputs=len(config[\"features\"]),\n",
        "        nb_neighbours=config[\"neighbours\"][1],\n",
        "        dynedge_layers=config[\"dynedge_layers\"],\n",
        "        post_processing_layer_sizes=config[\"post_processing_layer_sizes\"],\n",
        "        post_processing_transformer=config[\"post_processing_transformer\"],\n",
        "        readout_layer_sizes=config[\"readout_layer_sizes\"],\n",
        "        global_pooling=config.get(\"global_pooling\"),\n",
        "        features_subset=config[\"features_subset\"],\n",
        "        sensor_embedding=config.get(\"sensor_embedding\", False),\n",
        "        local_pooling=config.get(\"local_pooling\"),\n",
        "    )\n",
        "\n",
        "    loss_function = None\n",
        "    task = None\n",
        "    \n",
        "    if config[\"loss_function\"] == \"VonMisesFisher3DLoss\":\n",
        "        loss_function = VonMisesFisher3DLoss()\n",
        "\n",
        "    if config[\"loss_function\"] == \"CosineLoss\":\n",
        "        loss_function = CosineLoss()\n",
        "\n",
        "    if config[\"loss_function\"] == \"VMFCustomLoss\":\n",
        "        loss_function = VMFCustomLoss()\n",
        "\n",
        "    if config[\"loss_function\"] == \"CosineLoss2D\":\n",
        "        loss_function = CosineLoss2D()\n",
        "\n",
        "    if config[\"loss_function\"] == \"CrossEntropyLoss\":\n",
        "        loss_function = torch.nn.CrossEntropyLoss()        \n",
        "\n",
        "    if config[\"target\"] == 'direction':\n",
        "        if CFG.ANGLES == 'az,ze':\n",
        "            task = DirectionReconstructionWithKappa(\n",
        "                    hidden_size=gnn.nb_outputs,\n",
        "                    target_labels=config[\"target\"],\n",
        "                    loss_function=loss_function,       \n",
        "                )\n",
        "            prediction_columns = [config[\"target\"] + \"_x\", \n",
        "                                  config[\"target\"] + \"_y\", \n",
        "                                  config[\"target\"] + \"_z\", \n",
        "                                  config[\"target\"] + \"_kappa\" ]\n",
        "            additional_attributes = ['zenith', 'azimuth', 'event_id', 'sensor_id']\n",
        "        else:\n",
        "            task = DirectionReconstructionWithKappa2D(\n",
        "                hidden_size=gnn.nb_outputs,\n",
        "                target_labels=config[\"target\"],\n",
        "                loss_function=loss_function,       \n",
        "            )\n",
        "            prediction_columns = [config[\"target\"] + \"_x\", \n",
        "                                  config[\"target\"] + \"_y\", \n",
        "                                  config[\"target\"] + \"_kappa\" ]\n",
        "            additional_attributes = ['zenith', 'azimuth', 'event_id', 'sensor_id']\n",
        "\n",
        "    if config[\"target\"] == 'class_id':\n",
        "        DirectionReconstructionWithBins.nb_inputs = config[\"bin_num\"]**2\n",
        "        task = DirectionReconstructionWithBins(\n",
        "                                hidden_size=gnn.nb_outputs,\n",
        "                                target_labels=config[\"target\"],\n",
        "                                loss_function=loss_function)\n",
        "        \n",
        "        prediction_columns = [] \n",
        "        additional_attributes = ['zenith', 'azimuth', 'event_id', 'sensor_id']\n",
        "\n",
        "\n",
        "    model = StandardCustomModel(\n",
        "        detector=detector,\n",
        "        gnn=gnn,\n",
        "        tasks=[task],\n",
        "    )\n",
        "    model.prediction_columns = prediction_columns\n",
        "    model.additional_attributes = additional_attributes\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKJSmw7X-tjY"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHD4jGlw7KtT"
      },
      "outputs": [],
      "source": [
        "#@title cfg\n",
        "\n",
        "# Configuration\n",
        "CFG.NUM_EPOCHS = 10000\n",
        "CFG.NUM_STEPS = -1\n",
        "CFG.TRAIN_CFG = {\n",
        "        \"mode\": \"classification\", # regression/classification\n",
        "        \"features\": ['x', 'y', 'z', 'time', 'charge', 'auxiliary'], #['x', 'y', 'z', 'core', 'sc', 'abs', 'r', 'eff', 'time', 'charge', 'auxiliary'],  #['x', 'y', 'z', 'time', 'charge', 'auxiliary']\n",
        "        \"doms_agg\": False,\n",
        "        \"features_subset\": slice(0, 3),   # (0, 3)\n",
        "        \"neighbours\": (8,16),             # (8,8)\n",
        "        \"sensor_embedding\": False,         # False/True\n",
        "        \"dynedge_layers\": [\n",
        "                            {\n",
        "                              'type': 'DynEdgeConv',\n",
        "                              'sizes': (128,256),\n",
        "                              'nb_out': 256,\n",
        "                            },\n",
        "                            {\n",
        "                              'type': 'DynEdgeConv',\n",
        "                              'sizes': (336,256),\n",
        "                              'nb_out': 256,\n",
        "                            },\n",
        "                            {\n",
        "                              'type': 'DynEdgeConv',\n",
        "                              'sizes': (336,256),\n",
        "                              'nb_out': 256,\n",
        "                            },\n",
        "                            {\n",
        "                              'type': 'DynEdgeConv',\n",
        "                              'sizes': (336,256),\n",
        "                              'nb_out': 256,\n",
        "                            },\n",
        "                            {\n",
        "                              'type': 'DynEdgeConv',\n",
        "                              'sizes': (336,256),\n",
        "                              'nb_out': 256,\n",
        "                            },\n",
        "                          ],\n",
        "        \"post_processing_layer_sizes\": [2048,256],    # [336,256]\n",
        "        \"post_processing_transformer\": None, # None {\"d_model\": 256, \"nhead\": 4, \"num_layers\": 4, \"dim_feedforward\": 512}\n",
        "        \"local_pooling\": None,               # {\"type\": 'TopKPooling', \"k\": 4},\n",
        "        \"global_pooling\": {\"type\": \"simple\", \"schemes\": [\"min\",\"max\",\"mean\"], \"nb_out\": 768}, # {\"type\": \"simple\", \"schemes\": [\"min\",\"max\",\"mean\"], \"nb_out\": 768} {\"type\": \"GRU\", \"nb_in\": 256, \"nb_out\": 512}\n",
        "        \"readout_layer_sizes\": [512],     # 128\n",
        "        \"batch_size\": 400,                # 500\n",
        "        \"batch_train_size\": 400,          # for grad acc        \n",
        "        \"optimizer\": {\n",
        "                \"type\": 'adamW',           # lion/adam/adamW\n",
        "                \"lr\":  1e-05,             # 1e-03 1e-04 1e-05 1e-06\n",
        "                \"eps\": 1e-08              # 1e-03\n",
        "        },\n",
        "        \"augmentation\": {\n",
        "            \"az_rot\": False\n",
        "        }   \n",
        "}\n",
        "\n",
        "if CFG.TRAIN_CFG[\"mode\"] == \"regression\":\n",
        "    CFG.TRAIN_CFG[\"bin_num\"]       = None\n",
        "    CFG.TRAIN_CFG[\"target\"]        = \"direction\"\n",
        "    CFG.TRAIN_CFG[\"loss_function\"] = \"VonMisesFisher3DLoss\"\n",
        "\n",
        "if CFG.TRAIN_CFG[\"mode\"] == \"classification\":\n",
        "    CFG.TRAIN_CFG[\"bin_num\"]       = 24\n",
        "    CFG.TRAIN_CFG[\"target\"]        = \"class_id\"\n",
        "    CFG.TRAIN_CFG[\"loss_function\"] = \"CrossEntropyLoss\"\n",
        "\n",
        "CFG.TRAIN_CFG[\"scheduler\"] = {\n",
        "                \"type\": 'PiecewiseLinearLR',\n",
        "                \"milestones\": [0, (200_000 / CFG.TRAIN_CFG['batch_train_size']) / 2, ((200_000 / CFG.TRAIN_CFG['batch_train_size']) * 2000)],\n",
        "                \"factors\":    [1e-02, 1, 1e-02] #[1e-02, 1, 1e-02]\n",
        "        }\n",
        "\n",
        "sensors_data = get_sensors(CFG.TRAIN_CFG['features'][:-3])\n",
        "\n",
        "if CFG.USE_WANDB:\n",
        "    wandb_init()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZhJlXW5PMGQ"
      },
      "outputs": [],
      "source": [
        "#@title loaders\n",
        "\n",
        "#train_dataloader = build_dataloader(50, True)\n",
        "val_dataloader = build_dataloader(CFG.VAL_BATCH, False, CFG.TRAIN_CFG, CFG.VAL_EVENTS)\n",
        "\n",
        "print('valid batches: ', len(val_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj09I68sJcLu"
      },
      "outputs": [],
      "source": [
        "#batch = next(iter(val_dataloader))\n",
        "#batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkGdViiIeHBL"
      },
      "outputs": [],
      "source": [
        "#for batch in tqdm(val_dataloader):\n",
        "#  batch = batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sJsm9U53mf7"
      },
      "outputs": [],
      "source": [
        "#@title init\n",
        "\n",
        "model = build_model(config= CFG.TRAIN_CFG)\n",
        "\n",
        "if CFG.TRAIN_CFG['optimizer']['type'] == 'adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.TRAIN_CFG[\"optimizer\"][\"lr\"], eps=CFG.TRAIN_CFG[\"optimizer\"][\"eps\"]) \n",
        "\n",
        "if CFG.TRAIN_CFG['optimizer']['type'] == 'adamW':\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.TRAIN_CFG[\"optimizer\"][\"lr\"], eps=CFG.TRAIN_CFG[\"optimizer\"][\"eps\"]) \n",
        "\n",
        "if CFG.TRAIN_CFG['optimizer']['type'] == 'lion':\n",
        "    optimizer = Lion(model.parameters(), lr=CFG.TRAIN_CFG[\"optimizer\"][\"lr\"]) \n",
        "\n",
        "if CFG.TRAIN_CFG['scheduler']['type'] == 'PiecewiseLinearLR':\n",
        "    scheduler=PiecewiseLinearLR(optimizer, milestones=CFG.TRAIN_CFG['scheduler']['milestones'], factors=CFG.TRAIN_CFG['scheduler']['factors'])\n",
        "    \n",
        "model = model.to(device)\n",
        "\n",
        "summary(model)\n",
        "\n",
        "#summary(model, input_size=(CFG.TRAIN_CFG['batch_size'],CFG.MAX_PULSES_PER_EVENT, len(CFG.FEATURES)), col_names=[\"input_size\",\"output_size\",\"num_params\",\"mult_adds\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw98g1vkrbCE"
      },
      "outputs": [],
      "source": [
        "#@title test\n",
        "\n",
        "#batch = next(iter(val_dataloader))\n",
        "\n",
        "#batch.to(device)\n",
        "#out = model(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0MePzzU2kBH"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC6a92-52kBN"
      },
      "outputs": [],
      "source": [
        "#@title lib\n",
        "\n",
        "if CFG.TRAIN_CFG['mode'] == 'classification':\n",
        "    bin_num = CFG.TRAIN_CFG['bin_num']\n",
        "    azimuth_edges, zenith_edges = build_az_ze_edges(bin_num)\n",
        "    angle_bin_vector = build_angle_bin_vector(azimuth_edges.cpu().numpy(), zenith_edges.cpu().numpy(), bin_num)\n",
        "\n",
        "def augmentation(batch):\n",
        "    augm_cfg = CFG.TRAIN_CFG['augmentation']\n",
        "\n",
        "    # azimuth rotate\n",
        "    if augm_cfg['az_rot']:\n",
        "        rot_phi = torch.rand((1), device=device, dtype=torch.float32) * torch.pi * 2.0\n",
        "        rot_matrix = get_rot_matrix(rot_phi)\n",
        "        batch.x[:,:2] = batch.x[:,:2] @ rot_matrix\n",
        "        batch.direction[:,:2] = batch.direction[:,:2] @ rot_matrix\n",
        "\n",
        "    return batch\n",
        "\n",
        "def preds_to_vectors(preds):\n",
        "    preds = preds[0].detach()\n",
        "\n",
        "    if CFG.TRAIN_CFG['mode'] == 'regression':\n",
        "        vectors_pred = preds[:,:3]\n",
        "        kappa_preds =  preds[:,3]\n",
        "        return vectors_pred, kappa_preds, vectors_pred, kappa_preds\n",
        "\n",
        "    if CFG.TRAIN_CFG['mode'] == 'classification':\n",
        "        preds = torch.nn.functional.softmax(preds, dim=1)\n",
        "        vectors_pred_avg = code_to_vector(preds, bin_num, angle_bin_vector, max=False) \n",
        "        vectors_pred_max = code_to_vector(preds, bin_num, angle_bin_vector, max=True) \n",
        "        return vectors_pred_avg, None, vectors_pred_max, None\n",
        "\n",
        "def fit(model, loader, epoch, train=True, events_batch=None, batch_repeat=-1): \n",
        "    all_vectors_pred_max   = torch.tensor([], dtype=float).to(device)\n",
        "    all_vectors_pred_avg   = torch.tensor([], dtype=float).to(device)\n",
        "    all_kappa_pred_max     = torch.tensor([], dtype=float).to(device)\n",
        "    all_kappa_pred_avg     = torch.tensor([], dtype=float).to(device)\n",
        "\n",
        "    all_vectors_target = torch.tensor([], dtype=float).to(device)\n",
        "\n",
        "    tot_loss = 0\n",
        "    count = 0\n",
        "    total = CFG.NUM_STEPS if CFG.NUM_STEPS>0 and train else len(loader)\n",
        "    pbar = tqdm(enumerate(loader), total=total)\n",
        "    model.train(train)\n",
        "    if train:\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()     \n",
        "    batch_train_ratio = CFG.TRAIN_CFG['batch_train_size'] / CFG.TRAIN_CFG['batch_size'] \n",
        "    for steps, batch in pbar: \n",
        "        pbar.set_description(f\"epoch {epoch} (batch:{events_batch}:{batch_repeat}): {(tot_loss.cpu().item()/(steps) if steps > 0 else 0.0):.6f}\")\n",
        "        if steps == CFG.NUM_STEPS: #if train and steps == CFG.NUM_STEPS:\n",
        "            break\n",
        "\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # Forward propagation\n",
        "        if train:\n",
        "            batch = augmentation(batch)\n",
        "            preds = model(batch)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                preds = model(batch)\n",
        "\n",
        "        if CFG.TRAIN_CFG['mode'] == 'regression':\n",
        "            L = model.compute_loss(preds, batch)\n",
        "        else:\n",
        "            L = model._tasks[0]._loss_function(preds[0], batch.class_id)\n",
        "\n",
        "        if train:\n",
        "            # Calculating gradients\n",
        "            L.backward()\n",
        "            if (steps+1) % batch_train_ratio == 0:\n",
        "                # Update parameters\n",
        "                optimizer.step()  \n",
        "                # Update scheduler lr\n",
        "                scheduler.step()\n",
        "                # Clear gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        loss_val = L.detach()\n",
        "\n",
        "        vectors_pred_avg, kappa_pred_avg, vectors_pred_max, kappa_pred_max = preds_to_vectors(preds)\n",
        "\n",
        "        vectors_target = batch.direction\n",
        "\n",
        "        all_vectors_pred_avg   = torch.cat([all_vectors_pred_avg, vectors_pred_avg])\n",
        "        all_vectors_pred_max   = torch.cat([all_vectors_pred_max, vectors_pred_max])\n",
        "\n",
        "        if CFG.TRAIN_CFG['mode'] == 'regression':\n",
        "            all_kappa_pred_avg   = torch.cat([all_kappa_pred_avg, kappa_pred_avg])\n",
        "            all_kappa_pred_max   = torch.cat([all_kappa_pred_max, kappa_pred_max])\n",
        "\n",
        "        all_vectors_target = torch.cat([all_vectors_target, vectors_target])\n",
        "\n",
        "        tot_loss += loss_val\n",
        "        count+=1\n",
        "\n",
        "    error_avg, az_error_avg, ze_error_avg = angle_errors(all_vectors_pred_avg, all_vectors_target)\n",
        "    error_max, az_error_max, ze_error_max = angle_errors(all_vectors_pred_max, all_vectors_target)\n",
        "\n",
        "    kappa_mean = all_kappa_pred_avg.mean()\n",
        "\n",
        "    return tot_loss.item()/count, error_avg.item(), az_error_avg.item(), ze_error_avg.item(), error_max.item(), az_error_max.item(), ze_error_max.item(), kappa_mean.item()\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, val_loss, val_err_avg, val_err_max, val_kappa, best_epoch, best_val_loss, best_val_ads_avg, best_val_ads_max, batch_offset, batch_repeat, history, last):\n",
        "\n",
        "    exp_path  = CFG.CHECKPOINTS_PATH\n",
        "    if epoch == 1:\n",
        "        if path.isdir(exp_path):\n",
        "            shutil.rmtree(exp_path, ignore_errors=True)\n",
        "            \n",
        "    if not path.isdir(exp_path):\n",
        "        os.makedirs(exp_path, exist_ok=True)\n",
        "    \n",
        "    if last:\n",
        "        fname = f\"{exp_path}/model_exp_{CFG.EXP_ID}_{CFG.EXP_COMMENT}_last.pt\"\n",
        "    else:\n",
        "        fname = f\"{exp_path}/model_exp_{CFG.EXP_ID}_{CFG.EXP_COMMENT}_val_ads_avg_{val_err_avg:.4f}_val_ads_max_{val_err_max:.4f}_val_loss_{val_loss:.4f}_epoch_{epoch:04d}.pt\"\n",
        "        \n",
        "    print(f'save checkpoint: epoch: {epoch}, val_ads_avg: {val_err_avg:.4f}, val_ads_max: {val_err_max:.4f}, val_loss: {val_loss:.4f} to {fname}')\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_val_loss': best_val_loss,\n",
        "            'best_val_ads_avg': best_val_ads_avg,\n",
        "            'best_val_ads_max': best_val_ads_max,\n",
        "            'val_loss': val_loss,\n",
        "            'val_err_avg': val_err_avg,\n",
        "            'val_err_max': val_err_max,\n",
        "            'val_kappa': val_kappa,\n",
        "            'batch_offset': batch_offset,\n",
        "            'batch_repeat': batch_repeat,\n",
        "            'history': history,\n",
        "            'cfg': CFG.to_dict()\n",
        "            }, fname)\n",
        "\n",
        "def plot_train(history):\n",
        "\n",
        "    h = np.array(history)                               # learning output\n",
        "    plt.figure(figsize=(21,7), facecolor ='w')   \n",
        "\n",
        "    ax1 = plt.subplot(1,3,1);  \n",
        "    ax1.set( ylim=(4.7, 6.5), xlim=(0, h[-1,0]) )\n",
        "    ax1.grid(color='gray', linestyle='--', alpha=0.6)\n",
        "    ax1.set_title(f'trn_loss: {h[-1,1]:.4f}, val_loss: {h[-1,9]:.4f}, lr: {h[-1,17]:.4f}')\n",
        "\n",
        "    ax1.plot(h[:,0], h[:,1], \"-b\")   \n",
        "    ax1.plot(h[:,0], h[:,9], \"-g\")  \n",
        "    ax11 = ax1.twinx()\n",
        "    ax11.plot(h[:,0], h[:,17], \":k\")  \n",
        "    ax11.set_yscale('log');    \n",
        "\n",
        "    ax2 = plt.subplot(1,3,2)\n",
        "    ax2.set( ylim=(0.54, 1.10), xlim=(0, h[-1,0]) )\n",
        "    ax2.grid(color='gray', linestyle='--', alpha=0.6)\n",
        "    ax2.set_title(f'trn_ads_avg: {h[-1,2]:.4f}, val_ads_avg: {h[-1,10]:.4f}, val_kappa: {h[-1,16]:.4f}')\n",
        "    ax2.plot(h[:,0], h[:,2],  \"-b\")   \n",
        "    ax2.plot(h[:,0], h[:,10], \"-g\") \n",
        "    ax2.plot(h[:,0], h[:,3],  \":b\")   \n",
        "    ax2.plot(h[:,0], h[:,11], \":g\") \n",
        "    ax2.plot(h[:,0], h[:,4],  \"--b\")   \n",
        "    ax2.plot(h[:,0], h[:,12], \"--g\") \n",
        "    ax21 = ax2.twinx()\n",
        "    ax21.plot(h[:,0], h[:,16], \":r\")  \n",
        "\n",
        "    ax3 = plt.subplot(1,3,3)\n",
        "    ax3.set( ylim=(0.54, 1.10), xlim=(0, h[-1,0]) )\n",
        "    ax3.grid(color='gray', linestyle='--', alpha=0.6)\n",
        "    ax3.set_title(f'trn_ads_max: {h[-1,5]:.4f}, val_ads_max: {h[-1,13]:.4f}')\n",
        "    ax3.plot(h[:,0], h[:,5],  \"-b\")   \n",
        "    ax3.plot(h[:,0], h[:,13], \"-g\") \n",
        "    ax3.plot(h[:,0], h[:,6],  \":b\")   \n",
        "    ax3.plot(h[:,0], h[:,14], \":g\") \n",
        "    ax3.plot(h[:,0], h[:,7],  \"--b\")   \n",
        "    ax3.plot(h[:,0], h[:,15], \"--g\") \n",
        "\n",
        "\n",
        "    #pars = [ f\"{k:10s}: {v}\\n\" for k,v in CFG.items() ]\n",
        "    #ax1.text(h[0,0]+(h[-1,0]-h[0,0])*0.5, 0., \"\".join(pars), {'fontsize':12, 'fontname':'monospace'})\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eh7e5i62kBN"
      },
      "outputs": [],
      "source": [
        "#@title fit\n",
        "\n",
        "BATCH_REPEAT_CNT = 1\n",
        "\n",
        "history          = []\n",
        "epoch            = 1\n",
        "best_epoch       = 0\n",
        "best_val_loss    = 1000\n",
        "best_val_ads_avg = 1000\n",
        "best_val_ads_max = 1000\n",
        "batch_offset     = 0\n",
        "batch_repeat     = 0\n",
        "\n",
        "if CFG.RESUME:\n",
        "    #models = glob(resume_path + '*.pt')\n",
        "    #models.sort()\n",
        "    #resume_model = resume_path + 'model_exp_5_epoch_0107_val_ads_1.0854_trn_ads_1.0900_val_loss_1.7167_trn_loss_1.7201.pt'\n",
        "    #resume_model = models[-1]\n",
        "    state = torch.load(CFG.RESUME_MODEL)\n",
        "    epoch = state['epoch']\n",
        "    model.load_state_dict(state['model_state_dict'])\n",
        "    optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "    scheduler.load_state_dict(state['scheduler_state_dict'])\n",
        "    best_epoch = state['best_epoch']\n",
        "    best_val_loss = state['best_val_loss']\n",
        "    best_val_ads_avg = state['best_val_ads_avg']\n",
        "    best_val_ads_max = state['best_val_ads_max']\n",
        "    val_loss = state['val_loss']\n",
        "    val_err_avg = state['val_err_avg']\n",
        "    val_err_max = state['val_err_max']\n",
        "    val_kappa = state['val_kappa']\n",
        "    batch_offset = state['batch_offset']\n",
        "    batch_repeat = state['batch_repeat']\n",
        "    history = state['history']\n",
        "    cfg = state['cfg']\n",
        "    print(f'resume model: {CFG.RESUME_MODEL} with config: {cfg}')\n",
        "    print(f'from lr: {scheduler.get_last_lr()[0]}')\n",
        "    print(f'from epoch: {epoch}')\n",
        "\n",
        "    \n",
        "    print(f'\\tloss:     val: {val_loss:.4f} best: {best_val_loss:.4f}')\n",
        "    print(f'\\tads_avg:  val: {val_err_avg:.4f} best: {best_val_ads_avg:.4f}')\n",
        "    print(f'\\tads_max:  val: {val_err_max:.4f} best: {best_val_ads_max:.4f}')\n",
        "    print(f'\\tkappa:    val: {val_kappa:.4f}')\n",
        "    print(f'\\tbest epoch: {best_epoch}')\n",
        "\n",
        "    plot_train(history)\n",
        "    epoch += 1\n",
        "else:\n",
        "    print(f'train from scratch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opRTIoJr6G_5"
      },
      "outputs": [],
      "source": [
        "lr = 1e-06\n",
        "eps = 1e-03\n",
        "l2 = 0\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=lr, eps=eps, weight_decay=l2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0eONEpwFRVa"
      },
      "outputs": [],
      "source": [
        "CFG.NUM_STEPS = -1\n",
        "\n",
        "train_dataloader = None\n",
        "train_batch = None\n",
        "\n",
        "for epoch in range(epoch,CFG.NUM_EPOCHS+1):\n",
        "    batch_repeat += 1\n",
        "\n",
        "    if batch_repeat > BATCH_REPEAT_CNT:\n",
        "      batch_repeat = 1\n",
        "      batch_offset += 1\n",
        "    \n",
        "    cur_train_batch = CFG.BATCH_RANGE[0] + batch_offset\n",
        "    if cur_train_batch > CFG.BATCH_RANGE[1] - 1:\n",
        "      batch_offset = 0\n",
        "      cur_train_batch = CFG.BATCH_RANGE[0]\n",
        "      batch_repeat\n",
        "\n",
        "    #if train_batch != cur_train_batch:\n",
        "    #  train_batch = cur_train_batch\n",
        "    #  if train_dataloader:\n",
        "    #    del train_dataloader\n",
        "    #    gc.collect()\n",
        "    #  train_dataloader = build_dataloader(train_batch, True)\n",
        "\n",
        "    train_batch = cur_train_batch\n",
        "    if train_dataloader:\n",
        "        del train_dataloader\n",
        "        gc.collect()\n",
        "    \n",
        "    if CFG.SAMPLE_FILTER:\n",
        "        train_dataloader = build_dataloader(train_batch, False, CFG.TRAIN_CFG)\n",
        "        # check current metric\n",
        "        _, M_trn_before_filter, _, kappa_all, metrics_all = fit(model, train_dataloader, epoch, False, train_batch,batch_repeat)\n",
        "        #filter samples by kappa\n",
        "        samples_before = len(train_dataloader)\n",
        "        #indexes = (metrics_all<1.57).nonzero().squeeze().tolist()        \n",
        "        indexes = ((kappa_all>0.7) & (kappa_all<2.0)).nonzero().squeeze().tolist()        \n",
        "        train_dataloader = build_dataloader(train_batch, True, CFG.TRAIN_CFG, None, indexes)\n",
        "        samples_after = len(train_dataloader)\n",
        "        L_trn, M_trn, kappa_trn, _, _ = fit(model, train_dataloader, epoch, True, train_batch,batch_repeat)\n",
        "        print(f'sample filtering: before: {M_trn_before_filter:.5f}, after: {M_trn:.5f} samples: {(samples_after/samples_before):.5f}')\n",
        "        L_val, M_val, kappa_val, _, _ = fit(model, val_dataloader, epoch, False, CFG.VAL_BATCH,-1)\n",
        "    else:\n",
        "        train_dataloader = build_dataloader(train_batch, True, CFG.TRAIN_CFG)\n",
        "        trn_loss, trn_err_avg, trn_az_err_avg, trn_ze_err_avg, trn_err_max, trn_az_err_max, trn_ze_err_max, trn_kappa = fit(model, train_dataloader, epoch, True, train_batch,batch_repeat)\n",
        "        val_loss, val_err_avg, val_az_err_avg, val_ze_err_avg, val_err_max, val_az_err_max, val_ze_err_max, val_kappa = fit(model, val_dataloader, epoch, False, CFG.VAL_BATCH,-1)    \n",
        "\n",
        "\n",
        "    lr = scheduler.get_last_lr()[0]\n",
        "    history.append([epoch, \n",
        "                    trn_loss, trn_err_avg, trn_az_err_avg, trn_ze_err_avg, trn_err_max, trn_az_err_max, trn_ze_err_max, trn_kappa,\n",
        "                    val_loss, val_err_avg, val_az_err_avg, val_ze_err_avg, val_err_max, val_az_err_max, val_ze_err_max, val_kappa,\n",
        "                    lr])\n",
        "\n",
        "    if CFG.USE_WANDB:\n",
        "        wandb.log({\n",
        "                   \"trn_loss\": trn_loss, \n",
        "                   \"trn_err_avg\": trn_err_avg, \"trn_az_err_avg\": trn_az_err_avg, \"trn_ze_err_avg\": trn_ze_err_avg,\n",
        "                   \"trn_err_max\": trn_err_max, \"trn_az_err_max\": trn_az_err_max, \"trn_ze_err_max\": trn_ze_err_max,\n",
        "                   \"trn_kappa\": trn_kappa,\n",
        "                   \"val_loss\": val_loss, \n",
        "                   \"val_err_avg\": val_err_avg, \"val_az_err_avg\": val_az_err_avg, \"val_ze_err_avg\": val_ze_err_avg,\n",
        "                   \"val_err_max\": val_err_max, \"val_az_err_max\": val_az_err_max, \"val_ze_err_max\": val_ze_err_max,\n",
        "                   \"val_kappa\": val_kappa,\n",
        "                   \"lr\": lr\n",
        "                   })\n",
        "\n",
        "    print(f'epoch {epoch} (batch: {train_batch}, lr: {lr}):')    \n",
        "\n",
        "    if best_val_loss > val_loss:\n",
        "        print(f'\\t !!! val_loss improved from {best_val_loss:.4f} to {val_loss:.4f}')\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "    if best_val_ads_avg > val_err_avg:            \n",
        "        print(f'\\t !!! val_ads_avg improved from {best_val_ads_avg:.4f} to {val_err_avg:.4f}')\n",
        "        best_val_ads_avg = val_err_avg\n",
        "        best_epoch = epoch\n",
        "    if best_val_ads_max > val_err_max:            \n",
        "        print(f'\\t !!! val_ads_max improved from {best_val_ads_max:.4f} to {val_err_max:.4f}')\n",
        "        best_val_ads_max = val_err_max\n",
        "        best_epoch = epoch\n",
        "\n",
        "    print(f'\\tloss:     trn: {trn_loss:.4f} val: {val_loss:.4f} best: {best_val_loss:.4f}')\n",
        "    print(f'\\tads_avg:  trn: {trn_err_avg:.4f} val: {val_err_avg:.4f} best: {best_val_ads_avg:.4f}')\n",
        "    print(f'\\taz_avg:   trn: {trn_az_err_avg:.4f} val: {val_az_err_avg:.4f}')\n",
        "    print(f'\\tze_avg:   trn: {trn_ze_err_avg:.4f} val: {val_ze_err_avg:.4f}')\n",
        "    print(f'\\tads_max:  trn: {trn_err_max:.4f} val: {val_err_max:.4f} best: {best_val_ads_max:.4f}')\n",
        "    print(f'\\taz_max:   trn: {trn_az_err_max:.4f} val: {val_az_err_max:.4f}')\n",
        "    print(f'\\tze_max:   trn: {trn_ze_err_max:.4f} val: {val_ze_err_max:.4f}')\n",
        "    print(f'\\tkappa:    trn: {trn_kappa:.4f} val: {val_kappa:.4f}')\n",
        "    print(f'\\tbest epoch: {best_epoch}')\n",
        "\n",
        "    if best_epoch == epoch:\n",
        "      save_checkpoint(model, optimizer, epoch, val_loss, val_err_avg, val_err_max, val_kappa, best_epoch, best_val_loss, best_val_ads_avg, best_val_ads_max, batch_offset, batch_repeat, history, False)\n",
        "    else:\n",
        "      save_checkpoint(model, optimizer, epoch, val_loss, val_err_avg, val_err_max, val_kappa, best_epoch, best_val_loss, best_val_ads_avg, best_val_ads_max, batch_offset, batch_repeat, history, True)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        plot_train(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918yk9nt2kBT"
      },
      "source": [
        "# Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvXx82aU2kBT"
      },
      "outputs": [],
      "source": [
        "resume_model = CFG.RESUME_MODEL\n",
        "#resume_model = '/content/drive/MyDrive/work/projects/icecube/models/ice_gnn_v2_exp_1_aAZ_l4_e64_fs03_b200_lrs/model_exp_1_aAZ_l4_e64_fs03_b200_lrs_val_ads_0.7691_trn_ads_0.7982_val_loss_0.7409_trn_loss_0.7066_epoch_0246.pt'\n",
        "\n",
        "resume_state = torch.load(resume_model)\n",
        "model.load_state_dict(resume_state['model_state_dict'])\n",
        "#model.load_state_dict(resume_state)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG.NUM_STEPS = 10\n",
        "\n",
        "val_loss, val_err_avg, val_az_err_avg, val_ze_err_avg, val_err_max, val_az_err_max, val_ze_err_max, val_kappa = fit(model, val_dataloader, 100, False, CFG.VAL_BATCH)\n",
        "\n",
        "print(f'\\tloss:    val: {val_loss:.4f}')\n",
        "print(f'\\tads_avg: val: {val_err_avg:.4f}')\n",
        "print(f'\\taz_avg:  val: {val_az_err_avg:.4f}')\n",
        "print(f'\\tze_avg:  val: {val_ze_err_avg:.4f}')\n",
        "print(f'\\tads_max: val: {val_err_max:.4f}')\n",
        "print(f'\\taz_max:  val: {val_az_err_max:.4f}')\n",
        "print(f'\\tze_max:  val: {val_ze_err_max:.4f}')\n",
        "print(f'\\tkappa:   val: {val_kappa:.4f}')\n"
      ],
      "metadata": {
        "id": "dtzmHTlfS8tz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}